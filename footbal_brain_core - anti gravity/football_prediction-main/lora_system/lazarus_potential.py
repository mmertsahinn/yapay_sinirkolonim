"""
ğŸ§Ÿ LAZARUS POTENTIAL (Diriltme Potansiyeli!)
=============================================

"EN YÃœKSEK Ã–ÄRENME KAPASÄ°TESÄ°" OLANLAR DÄ°RÄ°LÄ°R!

Fisher Information Matrix (FIM) ile hesaplanan "Lazarus Î›":

Î›(lora) = det(F)^(1/k) Ã— exp(-Î² Ã— Entropy)

Nerede:
  â€¢ F: Fisher Information Matrix (Parametre hassasiyeti!)
  â€¢ k: Parametre sayÄ±sÄ±
  â€¢ Entropy: Sistemin dÃ¼zensizliÄŸi
  â€¢ Î²: Entropi ceza katsayÄ±sÄ±

YÃœksek Î› â†’ "Ã‡ok Ã¶ÄŸrenmiÅŸ ama kÃ¶tÃ¼ zamanda Ã¶ldÃ¼!" â†’ DÄ°RÄ°LT!
DÃ¼ÅŸÃ¼k Î› â†’ "Az deneyim, dar uzman!" â†’ DÄ°RÄ°LTME!
"""

import torch
import math
from typing import Dict, List, Tuple


class LazarusPotential:
    """
    Fisher Information bazlÄ± diriltme potansiyeli
    """
    
    def __init__(self, beta: float = 0.5):
        """
        Args:
            beta: Entropi ceza katsayÄ±sÄ± (0.5 = orta)
        """
        self.beta = beta
        print(f"ğŸ§Ÿ Lazarus Potential baÅŸlatÄ±ldÄ± (Î²={beta})")
    
    def calculate_lazarus_lambda(
        self,
        lora,
        fisher_info_matrix: torch.Tensor = None
    ) -> Dict:
        """
        Lazarus Î› hesapla!
        
        Args:
            lora: LoRA instance
            fisher_info_matrix: Fisher Info (None ise K-FAC ile hesapla!)
        
        Returns:
            {
                'lambda': Lazarus Î› deÄŸeri,
                'fisher_det': Fisher determinantÄ±,
                'entropy': Entropi,
                'learning_capacity': Ã–ÄŸrenme kapasitesi (Fisher!)
            }
        """
        # 1) FISHER INFO HESAPLA (K-FAC ile!)
        if fisher_info_matrix is None:
            from lora_system.kfac_fisher import kfac_fisher
            fisher_data = kfac_fisher.compute_fisher_kfac(lora)
            
            # Log-Determinant kullan (Daha stabil!)
            if 'fisher_logdet' in fisher_data:
                log_det = fisher_data['fisher_logdet']
                det_F = fisher_data.get('fisher_det', 0.0)
                
                # Geometrik ortalama yerine LOG-FISHER SCORE kullan!
                # det(F)^(1/k) yerine log(det(F)) / k
                rank = 16  # LoRA rank
                k = rank * 3  # 3 layer (fc1, fc2, fc3)
                
                # Log-space'de iÅŸlem yap (Fisher Score â‰ˆ 40-60 arasÄ± Ã§Ä±kar)
                fisher_score = log_det / k
                
                # ğŸ” DEBUG: Fisher hesaplama detaylarÄ±
                if hasattr(lora, 'birth_match'):
                    match_age = getattr(lora, '_current_match', 0) - lora.birth_match
                    if match_age % 50 == 0 or match_age < 5:
                        print(f"      ğŸ” Fisher Debug ({lora.name[:20]}):")
                        print(f"         â€¢ Log-Det: {log_det:.2f}")
                        print(f"         â€¢ Fisher Score (Log/k): {fisher_score:.3f}")
                        
                        # Yeni EÅŸikler (Log-Scale)
                        if fisher_score < 40.0:
                            print(f"         ğŸ’¬ Yorum: 'DÃ¼ÅŸÃ¼k Fisher - Az deneyim'")
                        elif fisher_score < 48.0:
                            print(f"         ğŸ’¬ Yorum: 'Orta Fisher - Standart Ã¶ÄŸrenme'")
                        elif fisher_score < 55.0:
                            print(f"         ğŸ’¬ Yorum: 'YÃ¼ksek Fisher - Ã‡ok iyi Ã¶ÄŸrenmiÅŸ!'")
                        else:
                            print(f"         ğŸŒŸ Yorum: 'EFSANE FISHER - Muazzam bilgi!'")
            else:
                # Fallback (Eski yÃ¶ntem - Ã§ok nadir)
                det_F = fisher_data.get('fisher_det', 1e-10)
                if det_F <= 0: det_F = 1e-10
                rank = 16
                k = rank * 3
                fisher_score = math.log(det_F) / k
        else:
            # EÄŸer Fisher matrisi verilmiÅŸse
            try:
                det_F = torch.det(fisher_info_matrix).item()
                if det_F <= 0: det_F = 1e-10
                k = fisher_info_matrix.shape[0]
                fisher_score = math.log(det_F) / k
            except:
                fisher_score = 40.0  # Hesaplanamazsa default (orta)
        
        # 3) ENTROPÄ° HESAPLA
        entropy = self._calculate_entropy(lora)
        
        # ğŸ” DEBUG: Entropy yorumu
        if hasattr(lora, 'birth_match'):
            match_age = getattr(lora, '_current_match', 0) - lora.birth_match
            if match_age % 50 == 0 or match_age < 5:
                print(f"         â€¢ Entropy: {entropy:.4f}")
                if entropy < 0.02:
                    print(f"         âš ï¸ UyarÄ±: 'Ã‡ok dÃ¼ÅŸÃ¼k entropy - Parametreler tekdÃ¼ze!'")
                elif entropy < 0.05:
                    print(f"         ğŸ’¬ Yorum: 'DÃ¼ÅŸÃ¼k entropy - Genetik Ã§eÅŸitlilik az'")
                elif entropy < 0.15:
                    print(f"         ğŸ’¬ Yorum: 'Orta entropy - Normal Ã§eÅŸitlilik'")
                else:
                    print(f"         âœ… Yorum: 'YÃ¼ksek entropy - Ä°yi Ã§eÅŸitlilik!'")
        
        # 4) LAZARUS Î› (Yeni FormÃ¼l)
        # Fisher Score 40-60 arasÄ± deÄŸiÅŸir.
        # Bunu 0-1 arasÄ±na normalize etmeye Ã§alÄ±ÅŸalÄ±m ama ucu aÃ§Ä±k kalsÄ±n.
        # Referans: 50.0 = Ä°yi
        
        # Normalize Score: (Fisher - 30) / 20  => 30->0.0, 50->1.0, 60->1.5
        normalized_fisher = max(0.0, (fisher_score - 30.0) / 20.0)
        
        # Lambda = Normalized_Fisher * Entropy_Penalty
        lambda_value = normalized_fisher * math.exp(-self.beta * entropy)
        
        # ğŸ” DEBUG: Final Lazarus Lambda yorumu
        if hasattr(lora, 'birth_match'):
            match_age = getattr(lora, '_current_match', 0) - lora.birth_match
            if match_age % 50 == 0 or match_age < 5:
                print(f"         â€¢ Lazarus Î›: {lambda_value:.3f}")
                if lambda_value < 0.5:
                    print(f"         ğŸ“‰ 'DÃœÅÃœK - Diriltme Ã¶nceliÄŸi dÃ¼ÅŸÃ¼k'")
                elif lambda_value < 0.8:
                    print(f"         ğŸ“Š 'ORTA - Standart aday'")
                elif lambda_value < 1.1:
                    print(f"         ğŸ“ˆ 'Ä°YÄ° - GÃ¼Ã§lÃ¼ aday'")
                else:
                    print(f"         ğŸŒŸ 'YÃœKSEK - Efsane! Mutlaka dirilt!'")
        
        # Fisher determinant deÄŸerini belirle
        # Ã–NEMLÄ°: det_F neden 0.0 olabilir?
        # 1. K-FAC kullanÄ±ldÄ±ÄŸÄ±nda: det_F hesaplanmaz, sadece logdet kullanÄ±lÄ±r (normal!)
        #    â†’ fisher_data.get('fisher_det', 0.0) = 0.0 (K-FAC logdet kullanÄ±r, det_F gerekmez)
        # 2. Fallback'te: det_F = 1e-10 (default deÄŸer)
        # 3. Fisher matrisi verilmiÅŸse: det_F = torch.det(...) hesaplanÄ±r
        # 4. Hesaplanamazsa: det_F tanÄ±mlÄ± deÄŸil, 0.0 dÃ¶ner
        # 
        # SONUÃ‡: fisher_det = 0.0 NORMALDÄ°R! K-FAC kullanÄ±ldÄ±ÄŸÄ±nda logdet kullanÄ±lÄ±r, det_F gerekmez.
        # AsÄ±l Ã¶nemli olan fisher_score (log-scale) deÄŸeridir!
        if 'det_F' in locals():
            fisher_det_value = det_F
        else:
            # Fisher determinant hesaplanamadÄ± (K-FAC kullanÄ±ldÄ±ÄŸÄ±nda normal)
            # K-FAC logdet kullanÄ±r, det_F hesaplanmaz (0.0 = K-FAC kullanÄ±ldÄ±, NORMAL!)
            fisher_det_value = 0.0
        
        return {
            'lambda': lambda_value,
            'fisher_det': fisher_det_value,  # Fisher determinant (0.0 = K-FAC kullanÄ±ldÄ± [NORMAL!], 1e-10 = fallback default)
            'fisher_term': fisher_score,  # Log-Scale Fisher Score (40-60 arasÄ± normal, 50 = iyi) - ASIL Ã–NEMLÄ° OLAN BU!
            'entropy': entropy,
            'learning_capacity': fisher_score,
            'formula': f"Î› = ({fisher_score:.1f}-30)/20 Ã— exp(-{self.beta}Ã—{entropy:.2f}) = {lambda_value:.3f}"
        }
    
    def check_population_diversity(self, population: List, match_idx: int):
        """
        PopÃ¼lasyon Ã§eÅŸitliliÄŸini kontrol et ve UYAR!
        
        Her 50 maÃ§ta Ã§aÄŸrÄ±lmalÄ±
        """
        if match_idx % 50 != 0 or match_idx == 0:
            return
        
        # TÃ¼m LoRA'larÄ±n Lazarus Lambda deÄŸerlerini topla
        lambdas = [getattr(lora, '_lazarus_lambda', 0.5) for lora in population]
        
        # Ä°statistikler
        import numpy as np
        mean_lambda = np.mean(lambdas)
        std_lambda = np.std(lambdas)
        unique_values = len(set([round(l, 2) for l in lambdas]))
        
        print(f"\nğŸ§¬ GENETÄ°K Ã‡EÅÄ°TLÄ°LÄ°K RAPORU (MaÃ§ #{match_idx}):")
        print(f"   {'â•'*60}")
        print(f"   â€¢ PopÃ¼lasyon: {len(population)} LoRA")
        print(f"   â€¢ Ortalama Lazarus Î›: {mean_lambda:.3f}")
        print(f"   â€¢ Standart Sapma: {std_lambda:.3f}")
        print(f"   â€¢ Benzersiz DeÄŸer: {unique_values}/{len(population)}")
        
        # YORUMLAR VE UYARILAR!
        if std_lambda < 0.05:
            print(f"\n   ğŸš¨ KRÄ°TÄ°K UYARI: GENETÄ°K Ã‡EÅÄ°TLÄ°LÄ°K Ã‡OK DÃœÅÃœK!")
            print(f"      ğŸ’¬ Yorum: 'TÃ¼m LoRA'lar birbirine Ã§ok benziyor!'")
            print(f"      ğŸ’¬ Sebep: Koloni mantÄ±ÄŸÄ± - Kimse Ã¶lmÃ¼yor, baskÄ± yok")
            print(f"      ğŸ’¡ Ä°leride dÃ¼ÅŸÃ¼nÃ¼lecek:")
            print(f"         â€¢ Mutasyon oranÄ±nÄ± artÄ±r")
            print(f"         â€¢ Diversity spawn ekle")
            print(f"         â€¢ Kara Veba'yÄ± bekle (doÄŸal eleme)")
        
        elif std_lambda < 0.10:
            print(f"\n   âš ï¸  UYARI: Genetik Ã§eÅŸitlilik az")
            print(f"      ğŸ’¬ Yorum: 'LoRA'lar benzeÅŸiyor'")
            print(f"      ğŸ’¡ Ä°leride dÃ¼ÅŸÃ¼nÃ¼lecek: Ã‡eÅŸitlilik artÄ±rma")
        
        elif std_lambda < 0.20:
            print(f"\n   âœ… Genetik Ã§eÅŸitlilik normal")
            print(f"      ğŸ’¬ Yorum: 'SaÄŸlÄ±klÄ± popÃ¼lasyon Ã§eÅŸitliliÄŸi'")
        
        else:
            print(f"\n   ğŸŒŸ Genetik Ã§eÅŸitlilik YÃœKSEK!")
            print(f"      ğŸ’¬ Yorum: 'Ã‡ok Ã§eÅŸitli popÃ¼lasyon - MÃ¼kemmel!'")
        
        print(f"   {'â•'*60}\n")
    
    def _calculate_entropy(self, lora) -> float:
        """
        LoRA'nÄ±n entropisini hesapla!
        
        Entropy = -Î£ p_i log(p_i)
        
        p_i = fitness daÄŸÄ±lÄ±mÄ± (baÅŸarÄ± Ã§eÅŸitliliÄŸi!)
        """
        # Fitness geÃ§miÅŸi
        if not hasattr(lora, 'fitness_history') or len(lora.fitness_history) < 5:
            return 0.5  # Default
        
        fitness_hist = lora.fitness_history[-100:]  # Son 100 maÃ§
        
        # Histogram (10 bin)
        hist, _ = torch.histogram(
            torch.tensor(fitness_hist, dtype=torch.float32),
            bins=10,
            range=(0.0, 1.0)
        )
        
        # Normalize et (olasÄ±lÄ±k!)
        p = hist.float() / (hist.sum() + 1e-8)
        
        # Shannon entropy
        entropy = -torch.sum(p * torch.log(p + 1e-8)).item()
        
        # Normalize (0-1 arasÄ±)
        # Max entropy = log(10) â‰ˆ 2.30
        entropy_normalized = entropy / 2.30
        
        return entropy_normalized
    
    def rank_for_resurrection(
        self,
        dead_loras: List,
        top_n: int = 10
    ) -> List[Tuple]:
        """
        Ã–lÃ¼ LoRA'larÄ± Lazarus Î›'ya gÃ¶re sÄ±rala!
        
        Args:
            dead_loras: Ã–lÃ¼ LoRA listesi
            top_n: Ä°lk kaÃ§ tane?
        
        Returns:
            [(lora, lambda_data), ...] (SÄ±ralÄ±!)
        """
        results = []
        
        for lora in dead_loras:
            try:
                lambda_data = self.calculate_lazarus_lambda(lora)
                results.append((lora, lambda_data))
            except Exception as e:
                # Hesaplanamazsa atla
                continue
        
        # Î›'ya gÃ¶re sÄ±rala (BÃ¼yÃ¼kten kÃ¼Ã§Ã¼ÄŸe!)
        results.sort(key=lambda x: x[1]['lambda'], reverse=True)
        
        return results[:top_n]
    
    def print_resurrection_ranking(self, ranked_loras: List[Tuple]):
        """
        Diriltme sÄ±ralamasÄ±nÄ± yazdÄ±r!
        """
        print("\n" + "="*80)
        print("ğŸ§Ÿ LAZARUS POTENTIAL SIRALAMA (Diriltme Ã–nceliÄŸi!)")
        print("="*80)
        print(f"{'Rank':<6} {'LoRA':<25} {'Î›':<8} {'Fisher':<10} {'Entropy':<10} {'Kapasite':<10}")
        print("-"*80)
        
        for idx, (lora, data) in enumerate(ranked_loras, start=1):
            print(f"#{idx:<5} {lora.name[:24]:<25} {data['lambda']:<8.3f} "
                  f"{data['fisher_term']:<10.3f} {data['entropy']:<10.2f} "
                  f"{'YÃ¼ksek!' if data['learning_capacity'] > 1.0 else 'Orta':<10}")
        
        print("="*80)
        print(f"ğŸ’¡ YORUM:")
        print(f"   â€¢ YÃ¼ksek Î› = Ã‡ok deneyim + DÃ¼ÅŸÃ¼k entropi = DÄ°RÄ°LT!")
        print(f"   â€¢ Fisher > 1.0 = GeniÅŸ parametre uzayÄ± keÅŸfetti!")
        print(f"   â€¢ Entropi dÃ¼ÅŸÃ¼k = Organize Ã¶ÄŸrenmiÅŸ!")
        print("="*80 + "\n")


# Global instance
lazarus_potential = LazarusPotential(beta=0.5)


