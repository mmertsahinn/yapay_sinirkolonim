"""
üï∏Ô∏è ADVANCED SOCIAL NETWORK - Neural Similarity & Thinking Patterns
====================================================================

Geli≈ümi≈ü sosyal aƒü: Benzer d√º≈ü√ºnenler birbirine √ßekilmeli.

√ñzellikler:
‚úÖ Similarity-based attraction
‚úÖ Neural similarity (n√∂ron yapƒ±larƒ±nƒ±n benzerliƒüi)
‚úÖ Thinking pattern clustering
‚úÖ Dynamic bond formation based on neural/thinking similarity

Mevcut social_network.py'yi geni≈ületir.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict
import math

# Import base social network
from .social_network import SocialNetwork

# Import related modules
from .thinking_patterns import ThinkingPattern, EvolvableThinkingSystem


class NeuralSimilarityCalculator:
    """
    N√∂ron yapƒ±larƒ±nƒ±n benzerliƒüini hesaplar
    
    ƒ∞ki LoRA'nƒ±n n√∂ron mimarisi ne kadar benzer?
    """
    
    def __init__(self):
        print("‚úÖ NeuralSimilarityCalculator initialized")
    
    def calculate_architecture_similarity(self, lora_i, lora_j) -> float:
        """
        Mimari benzerliƒüi hesapla
        
        Args:
            lora_i: LoRA instance
            lora_j: LoRA instance
            
        Returns:
            Similarity score (0-1)
        """
        # N√∂ron sayƒ±larƒ±
        dim_i = getattr(lora_i, 'hidden_dim', 128)
        dim_j = getattr(lora_j, 'hidden_dim', 128)
        
        # Katman sayƒ±larƒ±
        layers_i = self._count_layers(lora_i)
        layers_j = self._count_layers(lora_j)
        
        # Dimension similarity
        dim_sim = 1.0 - abs(dim_i - dim_j) / max(dim_i, dim_j, 1)
        
        # Layer similarity
        layer_sim = 1.0 if layers_i == layers_j else 0.5
        
        # Combined similarity
        similarity = (dim_sim * 0.7 + layer_sim * 0.3)
        
        return max(0.0, min(1.0, similarity))
    
    def _count_layers(self, lora) -> int:
        """Katman sayƒ±sƒ±nƒ± hesapla"""
        count = 0
        for attr in ['fc1', 'fc2', 'fc3']:
            if hasattr(lora, attr):
                count += 1
        return count
    
    def calculate_parameter_similarity(self, lora_i, lora_j) -> float:
        """
        Parametre benzerliƒüini hesapla (cosine similarity)
        
        Args:
            lora_i: LoRA instance
            lora_j: LoRA instance
            
        Returns:
            Similarity score (0-1)
        """
        try:
            params_i = lora_i.get_all_lora_params()
            params_j = lora_j.get_all_lora_params()
            
            # Flatten parameters
            vec_i = self._flatten_params(params_i)
            vec_j = self._flatten_params(params_j)
            
            # Cosine similarity
            vec_i_norm = vec_i / (torch.norm(vec_i) + 1e-8)
            vec_j_norm = vec_j / (torch.norm(vec_j) + 1e-8)
            
            similarity = torch.dot(vec_i_norm, vec_j_norm).item()
            
            return max(0.0, min(1.0, (similarity + 1.0) / 2.0))  # -1,1 ‚Üí 0,1
        
        except Exception as e:
            return 0.5  # Default similarity
    
    def _flatten_params(self, params: Dict) -> torch.Tensor:
        """Parametreleri d√ºzle≈ütir"""
        param_list = []
        for layer in ['fc1', 'fc2', 'fc3']:
            if layer in params:
                for matrix in ['lora_A', 'lora_B']:
                    if matrix in params[layer]:
                        param_list.append(params[layer][matrix].flatten())
        
        if param_list:
            return torch.cat(param_list)
        else:
            return torch.tensor([0.0])


class ThinkingPatternClustering:
    """
    D√º≈ü√ºnme bi√ßimlerine g√∂re grupla≈üma
    
    Benzer d√º≈ü√ºnen LoRA'lar birbirine √ßekilmeli
    """
    
    def __init__(self):
        print("‚úÖ ThinkingPatternClustering initialized")
    
    def calculate_thinking_similarity(self, lora_i, lora_j) -> float:
        """
        D√º≈ü√ºnme bi√ßimi benzerliƒüi
        
        Args:
            lora_i: LoRA instance
            lora_j: LoRA instance
            
        Returns:
            Similarity score (0-1)
        """
        # Thinking system'leri al
        thinking_i = getattr(lora_i, 'thinking_system', None)
        thinking_j = getattr(lora_j, 'thinking_system', None)
        
        if thinking_i is None or thinking_j is None:
            return 0.5  # Default
        
        # Primary pattern similarity
        if thinking_i.primary_pattern == thinking_j.primary_pattern:
            primary_sim = 1.0
        else:
            primary_sim = 0.3  # Farklƒ± pattern'ler
        
        # Pattern weights similarity
        weights_i = thinking_i.pattern_weights
        weights_j = thinking_j.pattern_weights
        
        # Cosine similarity of weight vectors
        weights_i_vec = torch.tensor([weights_i.get(p, 0.0) for p in ThinkingPattern])
        weights_j_vec = torch.tensor([weights_j.get(p, 0.0) for p in ThinkingPattern])
        
        weights_i_norm = weights_i_vec / (torch.norm(weights_i_vec) + 1e-8)
        weights_j_norm = weights_j_vec / (torch.norm(weights_j_vec) + 1e-8)
        
        weights_sim = torch.dot(weights_i_norm, weights_j_norm).item()
        weights_sim = (weights_sim + 1.0) / 2.0  # -1,1 ‚Üí 0,1
        
        # Combined similarity
        similarity = primary_sim * 0.4 + weights_sim * 0.6
        
        return max(0.0, min(1.0, similarity))
    
    def find_thinking_clusters(self, population: List) -> Dict[ThinkingPattern, List[str]]:
        """
        D√º≈ü√ºnme bi√ßimlerine g√∂re k√ºmeler bul
        
        Args:
            population: LoRA pop√ºlasyonu
            
        Returns:
            Pattern ‚Üí LoRA IDs mapping
        """
        clusters = defaultdict(list)
        
        for lora in population:
            thinking_system = getattr(lora, 'thinking_system', None)
            if thinking_system:
                primary_pattern = thinking_system.primary_pattern
                clusters[primary_pattern].append(lora.id)
            else:
                # Default cluster
                clusters[ThinkingPattern.HOLISTIC].append(lora.id)
        
        return dict(clusters)


class AdvancedSocialNetwork(SocialNetwork):
    """
    Geli≈ümi≈ü Sosyal Aƒü
    
    Mevcut SocialNetwork'√º geni≈ületir:
    - Neural similarity
    - Thinking pattern clustering
    - Similarity-based attraction
    """
    
    def __init__(self):
        super().__init__()
        
        # Advanced components
        self.neural_similarity = NeuralSimilarityCalculator()
        self.thinking_clustering = ThinkingPatternClustering()
        
        # Similarity cache (performance i√ßin)
        self.similarity_cache: Dict[Tuple[str, str], Dict] = {}
        
        # Cluster tracking
        self.thinking_clusters: Dict[ThinkingPattern, List[str]] = {}
        
        # Attraction weights
        self.ALPHA_NEURAL = 0.25  # Neural similarity weight
        self.ALPHA_THINKING = 0.25  # Thinking similarity weight
        self.ALPHA_BASE = 0.50  # Base social network weight
        
        print("="*80)
        print("üï∏Ô∏è ADVANCED SOCIAL NETWORK INITIALIZED")
        print("="*80)
        print(f"   Neural similarity weight: {self.ALPHA_NEURAL}")
        print(f"   Thinking similarity weight: {self.ALPHA_THINKING}")
        print(f"   Base network weight: {self.ALPHA_BASE}")
        print("="*80)
    
    def update_social_bond(self, lora_i: Any, lora_j: Any, match_result: Dict) -> float:
        """
        Geli≈ümi≈ü sosyal baƒü g√ºncelleme
        
        Neural similarity ve thinking pattern benzerliƒüi eklenir
        """
        # Base bond (parent class'tan)
        base_bond = super().update_social_bond(lora_i, lora_j, match_result)
        
        # Neural similarity
        neural_sim = self.neural_similarity.calculate_architecture_similarity(lora_i, lora_j)
        
        # Parameter similarity
        param_sim = self.neural_similarity.calculate_parameter_similarity(lora_i, lora_j)
        
        neural_composite = (neural_sim * 0.6 + param_sim * 0.4)
        
        # Thinking pattern similarity
        thinking_sim = self.thinking_clustering.calculate_thinking_similarity(lora_i, lora_j)
        
        # Combined bond strength
        enhanced_bond = (
            self.ALPHA_BASE * base_bond +
            self.ALPHA_NEURAL * neural_composite +
            self.ALPHA_THINKING * thinking_sim
        )
        
        # Cache similarity
        key = tuple(sorted((lora_i.id, lora_j.id)))
        self.similarity_cache[key] = {
            'neural': neural_sim,
            'parameter': param_sim,
            'thinking': thinking_sim,
            'base_bond': base_bond,
            'enhanced_bond': enhanced_bond
        }
        
        # Update bond with enhanced value
        self.bonds[key] = enhanced_bond
        
        return enhanced_bond
    
    def update_thinking_clusters(self, population: List):
        """
        D√º≈ü√ºnme bi√ßimi k√ºmelerini g√ºncelle
        
        Args:
            population: LoRA pop√ºlasyonu
        """
        self.thinking_clusters = self.thinking_clustering.find_thinking_clusters(population)
        
        print(f"   üß† Thinking clusters updated:")
        for pattern, lora_ids in self.thinking_clusters.items():
            print(f"      {pattern.value}: {len(lora_ids)} LoRAs")
    
    def get_similarity_based_cluster(self, lora_id: str, threshold: float = 0.6) -> List[str]:
        """
        Benzerlik bazlƒ± k√ºme (neural + thinking)
        
        Args:
            lora_id: LoRA ID
            threshold: Benzerlik e≈üiƒüi
            
        Returns:
            Benzer LoRA ID'leri
        """
        similar = []
        
        for key, cache_data in self.similarity_cache.items():
            if lora_id not in key:
                continue
            
            other_id = key[1] if key[0] == lora_id else key[0]
            
            # Combined similarity
            combined_sim = (
                cache_data['neural'] * 0.4 +
                cache_data['thinking'] * 0.4 +
                cache_data['base_bond'] * 0.2
            )
            
            if combined_sim > threshold:
                similar.append(other_id)
        
        return similar
    
    def apply_similarity_based_attraction(self, population: List, attraction_strength: float = 0.05):
        """
        Benzerlik bazlƒ± √ßekim uygula
        
        Benzer d√º≈ü√ºnen/n√∂ron yapƒ±lƒ± LoRA'lar birbirine √ßekilir
        
        Args:
            population: LoRA pop√ºlasyonu
            attraction_strength: √áekim g√ºc√º
        """
        attraction_count = 0
        
        # Her benzer √ßift i√ßin
        for key, cache_data in self.similarity_cache.items():
            if cache_data['enhanced_bond'] < 0.7:  # Sadece g√º√ßl√º baƒülar
                continue
            
            id1, id2 = key
            lora_i = next((l for l in population if l.id == id1), None)
            lora_j = next((l for l in population if l.id == id2), None)
            
            if not lora_i or not lora_j:
                continue
            
            # Neural attraction: N√∂ron yapƒ±larƒ± birbirine yakla≈üƒ±r
            if cache_data['neural'] > 0.6:
                self._apply_neural_attraction(lora_i, lora_j, attraction_strength)
                attraction_count += 1
            
            # Thinking attraction: D√º≈ü√ºnme bi√ßimleri birbirine yakla≈üƒ±r
            if cache_data['thinking'] > 0.6:
                self._apply_thinking_attraction(lora_i, lora_j, attraction_strength)
        
        if attraction_count > 0:
            print(f"   üß≤ Similarity-based attraction: {attraction_count} pairs")
    
    def _apply_neural_attraction(self, lora_i, lora_j, strength: float):
        """N√∂ron yapƒ±larƒ± birbirine yakla≈ütƒ±r"""
        # Hidden dimension convergence
        if hasattr(lora_i, 'hidden_dim') and hasattr(lora_j, 'hidden_dim'):
            dim_i = lora_i.hidden_dim
            dim_j = lora_j.hidden_dim
            
            # Average'e doƒüru √ßek
            avg_dim = int((dim_i + dim_j) / 2)
            
            # Gradual convergence
            if abs(dim_i - dim_j) > 10:  # Sadece b√ºy√ºk farklar i√ßin
                # ≈ûimdilik sadece log, ger√ßek deƒüi≈üim karma≈üƒ±k
                pass
    
    def _apply_thinking_attraction(self, lora_i, lora_j, strength: float):
        """D√º≈ü√ºnme bi√ßimleri birbirine yakla≈ütƒ±r"""
        thinking_i = getattr(lora_i, 'thinking_system', None)
        thinking_j = getattr(lora_j, 'thinking_system', None)
        
        if thinking_i is None or thinking_j is None:
            return
        
        # Pattern weights'leri birbirine yakla≈ütƒ±r
        for pattern in ThinkingPattern:
            if pattern in thinking_i.pattern_weights and pattern in thinking_j.pattern_weights:
                w_i = thinking_i.pattern_weights[pattern]
                w_j = thinking_j.pattern_weights[pattern]
                
                # Blend: (1-Œ±) √ó w_i + Œ± √ó w_j
                avg_weight = (w_i + w_j) / 2
                
                thinking_i.pattern_weights[pattern] = (1 - strength) * w_i + strength * avg_weight
                thinking_j.pattern_weights[pattern] = (1 - strength) * w_j + strength * avg_weight
        
        # Update primary patterns
        thinking_i.primary_pattern = max(thinking_i.pattern_weights.items(), key=lambda x: x[1])[0]
        thinking_j.primary_pattern = max(thinking_j.pattern_weights.items(), key=lambda x: x[1])[0]
    
    def get_bond_strength(self, id1: str, id2: str) -> float:
        """Sosyal baƒü g√ºc√ºn√º al (override for enhanced bonds)"""
        return super().get_bond_strength(id1, id2)
    
    def get_social_cluster(self, lora_id: str, threshold: float = 0.5) -> List[str]:
        """Sosyal k√ºme (enhanced version)"""
        # Base cluster
        base_cluster = super().get_social_cluster(lora_id, threshold)
        
        # Similarity-based cluster
        similarity_cluster = self.get_similarity_based_cluster(lora_id, threshold)
        
        # Combine (unique)
        combined = list(set(base_cluster + similarity_cluster))
        
        return combined
    
    def get_network_statistics(self) -> Dict:
        """Aƒü istatistikleri"""
        stats = {
            'total_bonds': len(self.bonds),
            'strong_bonds': sum(1 for b in self.bonds.values() if b > 0.7),
            'thinking_clusters': {
                pattern.value: len(ids) 
                for pattern, ids in self.thinking_clusters.items()
            },
            'similarity_cache_size': len(self.similarity_cache)
        }
        
        return stats


# Global instance
_global_advanced_social_network = None


def get_advanced_social_network() -> AdvancedSocialNetwork:
    """Global advanced social network instance"""
    global _global_advanced_social_network
    if _global_advanced_social_network is None:
        _global_advanced_social_network = AdvancedSocialNetwork()
    return _global_advanced_social_network


