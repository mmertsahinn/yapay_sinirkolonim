"""
ğŸ•¸ï¸ BACKGROUND SIEVE SYSTEM - KATEGORÄ°ZASYON ELEÄÄ°
==================================================

KullanÄ±cÄ±nÄ±n istediÄŸi "Arka plan elek sistemi".

LoRA'larÄ± sadece etiketlerine gÃ¶re deÄŸil, gerÃ§ek davranÄ±ÅŸlarÄ±na (prediction vectors)
ve hatalarÄ±na gÃ¶re analiz edip "Kabilelere" (Tribes) ayÄ±rÄ±r.

Bu sistem sÃ¼rekli Ã§alÄ±ÅŸÄ±r ve LoRA'larÄ± doÄŸru kutulara yerleÅŸtirir.

Bilimsel Temel:
- Unsupervised Learning (Clustering)
- Behavioral Analysis
- Pattern Recognition
- DBSCAN: Density-Based Spatial Clustering of Applications with Noise

Ã–zellikler:
âœ… Prediction history tracking (circular buffer)
âœ… Error history tracking
âœ… Feature extraction (avg_error, home_bias, draw_bias, risk_appetite, confidence)
âœ… DBSCAN clustering (doÄŸal kÃ¼meler)
âœ… Tribe etiketleme (behavioral categories)
âœ… Lazy update (performance iÃ§in)
"""

import numpy as np
from sklearn.cluster import DBSCAN, KMeans
from typing import List, Dict, Any, Optional
from collections import defaultdict, deque
import warnings
warnings.filterwarnings('ignore')  # DBSCAN convergence warnings


class BackgroundSieve:
    """
    Arka Plan Elek Sistemi
    
    LoRA'larÄ± davranÄ±ÅŸlarÄ±na gÃ¶re kategorize eder.
    """
    
    def __init__(self, buffer_size: int = 50, update_frequency: int = 10, min_samples_for_clustering: int = 10):
        """
        Args:
            buffer_size: Her LoRA iÃ§in tutulacak prediction sayÄ±sÄ±
            update_frequency: KaÃ§ maÃ§ta bir clustering yapÄ±lacak
            min_samples_for_clustering: Clustering iÃ§in minimum Ã¶rnek sayÄ±sÄ±
        """
        self.buffer_size = buffer_size
        self.update_frequency = update_frequency
        self.min_samples_for_clustering = min_samples_for_clustering
        
        # Prediction history (circular buffer)
        self.prediction_history = defaultdict(lambda: deque(maxlen=buffer_size))
        
        # Error history (circular buffer)
        self.error_history = defaultdict(lambda: deque(maxlen=buffer_size))
        
        # Clustering results
        self.clusters = {}  # {lora_id: cluster_id}
        self.cluster_profiles = {}  # {cluster_id: {'name': 'tribe_elite', 'features': [...]}}
        
        # Update tracking
        self.last_update_match = 0
        self.population_snapshot = {}  # Son clustering'deki popÃ¼lasyon
        
        print(f"âœ… BackgroundSieve initialized (buffer={buffer_size}, update_freq={update_frequency})")
    
    def record_behavior(self, 
                       lora_id: str, 
                       prediction_vector: np.ndarray, 
                       is_correct: bool, 
                       error_margin: float):
        """
        Her maÃ§ sonrasÄ± LoRA'nÄ±n davranÄ±ÅŸÄ±nÄ± kaydet.
        
        Args:
            lora_id: LoRA ID
            prediction_vector: [p_home, p_draw, p_away] (3 boyut)
            is_correct: DoÄŸru tahmin mi?
            error_margin: Hata marjÄ± (0-1, yanlÄ±ÅŸsa confidence, doÄŸruysa 0)
        """
        # Prediction history
        self.prediction_history[lora_id].append(prediction_vector.copy())
        
        # Error history (yanlÄ±ÅŸsa error_margin, doÄŸruysa 0)
        error_value = error_margin if not is_correct else 0.0
        self.error_history[lora_id].append(error_value)
    
    def _extract_features(self, lora_id: str) -> Optional[np.ndarray]:
        """
        Bir LoRA iÃ§in feature extraction
        
        Features:
        1. avg_error: Ortalama hata (0-1)
        2. home_bias: Home tercih oranÄ± (0-1)
        3. draw_bias: Draw tercih oranÄ± (0-1)
        4. risk_appetite: Varyans (yÃ¼ksek = dalgalÄ±, dÃ¼ÅŸÃ¼k = tutarlÄ±)
        5. confidence_avg: Ortalama gÃ¼ven (0-1)
        
        Returns:
            Feature vector [5] veya None (yeterli veri yoksa)
        """
        if len(self.prediction_history[lora_id]) < self.min_samples_for_clustering:
            return None
        
        preds = np.array(list(self.prediction_history[lora_id]))
        errors = np.array(list(self.error_history[lora_id]))
        
        # Feature 1: Ortalama hata
        avg_error = np.mean(errors)
        
        # Feature 2: Home bias (home tercih oranÄ±)
        home_bias = np.mean(preds[:, 0])  # Ä°lk sÃ¼tun = home
        
        # Feature 3: Draw bias
        draw_bias = np.mean(preds[:, 1])  # Ä°kinci sÃ¼tun = draw
        
        # Feature 4: Risk appetite (varyans)
        # YÃ¼ksek varyans = Ã§ok emin veya Ã§ok kararsÄ±z deÄŸil, dalgalÄ± tahminler
        risk_appetite = np.var(preds.flatten())
        
        # Feature 5: Ortalama gÃ¼ven (max probability)
        confidence_avg = np.mean(np.max(preds, axis=1))
        
        features = np.array([
            avg_error,
            home_bias,
            draw_bias,
            risk_appetite,
            confidence_avg
        ], dtype=np.float32)
        
        return features
    
    def _generate_tribe_tag(self, cluster_features: np.ndarray) -> str:
        """
        KÃ¼me Ã¶zelliklerine gÃ¶re tribe etiketi oluÅŸtur
        
        Args:
            cluster_features: [avg_error, home_bias, draw_bias, risk_appetite, confidence_avg]
            
        Returns:
            Tribe tag string
        """
        avg_err, home, draw, risk, conf = cluster_features
        
        # Elite: DÃ¼ÅŸÃ¼k hata, yÃ¼ksek gÃ¼ven
        if avg_err < 0.3 and conf > 0.7:
            return "tribe_elite"
        
        # Overconfident: YÃ¼ksek gÃ¼ven ama yÃ¼ksek hata
        if conf > 0.8 and avg_err > 0.5:
            return "tribe_overconfident"
        
        # Chaotic: YÃ¼ksek risk (varyans)
        if risk > 0.1:
            return "tribe_chaotic"
        
        # Home Lover: Home bias yÃ¼ksek
        if home > 0.5:
            return "tribe_home_lover"
        
        # Draw Hunter: Draw bias yÃ¼ksek
        if draw > 0.4:
            return "tribe_draw_hunter"
        
        # Conservative: DÃ¼ÅŸÃ¼k risk, orta gÃ¼ven
        if risk < 0.05 and 0.5 < conf < 0.7:
            return "tribe_conservative"
        
        # Average: DiÄŸerleri
        return "tribe_average"
    
    def _should_update(self, current_match: int, population: List[Any]) -> bool:
        """
        Clustering gÃ¼ncellemesi gerekli mi?
        
        KoÅŸullar:
        1. update_frequency maÃ§ geÃ§ti
        2. PopÃ¼lasyon %20'den fazla deÄŸiÅŸti
        """
        # KoÅŸul 1: Frequency check
        if current_match - self.last_update_match >= self.update_frequency:
            return True
        
        # KoÅŸul 2: PopÃ¼lasyon deÄŸiÅŸimi
        current_ids = {lora.id for lora in population}
        previous_ids = set(self.population_snapshot.keys())
        
        if len(previous_ids) == 0:
            return True  # Ä°lk kez
        
        # DeÄŸiÅŸim oranÄ±
        new_loras = current_ids - previous_ids
        removed_loras = previous_ids - current_ids
        change_ratio = (len(new_loras) + len(removed_loras)) / max(len(previous_ids), 1)
        
        if change_ratio > 0.2:  # %20'den fazla deÄŸiÅŸim
            return True
        
        return False
    
    def run_sieve(self, population: List[Any], current_match: int = 0, force_update: bool = False):
        """
        EleÄŸi Ã§alÄ±ÅŸtÄ±r: LoRA'larÄ± kÃ¼melere ayÄ±r.
        
        Process:
        1. Update gerekli mi kontrol et (lazy update)
        2. Feature extraction (yeterli verisi olanlar iÃ§in)
        3. DBSCAN clustering
        4. Tribe etiketleme
        5. LoRA'lara tag ekle
        
        Args:
            population: LoRA popÃ¼lasyonu
            current_match: Mevcut maÃ§ sayÄ±sÄ±
            force_update: Zorla gÃ¼ncelle (lazy update'Ä± bypass et)
        """
        if len(population) < 5:
            return  # Yeterli popÃ¼lasyon yok
        
        # Lazy update kontrolÃ¼
        if not force_update and not self._should_update(current_match, population):
            return  # HenÃ¼z gÃ¼ncelleme gerekmiyor
        
        # Feature extraction
        features = []
        valid_loras = []
        
        for lora in population:
            lora_features = self._extract_features(lora.id)
            if lora_features is not None:
                features.append(lora_features)
                valid_loras.append(lora)
        
        if len(features) < 5:
            return  # Yeterli feature yok
        
        X = np.array(features)
        
        # Feature normalization (DBSCAN iÃ§in Ã¶nemli!)
        # Her feature'Ä± 0-1 arasÄ±na normalize et
        X_min = X.min(axis=0, keepdims=True)
        X_max = X.max(axis=0, keepdims=True)
        X_range = X_max - X_min
        X_range[X_range == 0] = 1  # Division by zero Ã¶nleme
        X_normalized = (X - X_min) / X_range
        
        # DBSCAN clustering (Density-based, noise handling)
        # eps: KomÅŸuluk yarÄ±Ã§apÄ± (normalize edilmiÅŸ feature space'de)
        # min_samples: Minimum komÅŸu sayÄ±sÄ± (kÃ¼me iÃ§in)
        clustering = DBSCAN(eps=0.3, min_samples=2, metric='euclidean')
        labels = clustering.fit_predict(X_normalized)
        
        # SonuÃ§larÄ± iÅŸle
        new_clusters = {}
        cluster_feature_means = defaultdict(list)
        
        for i, label in enumerate(labels):
            lora = valid_loras[i]
            
            if label != -1:  # Noise deÄŸilse (kÃ¼me iÃ§inde)
                new_clusters[lora.id] = int(label)
                cluster_feature_means[label].append(features[i])
        
        # Cluster profilleri oluÅŸtur
        for cluster_id, cluster_feats in cluster_feature_means.items():
            cluster_mean = np.mean(cluster_feats, axis=0)
            tribe_tag = self._generate_tribe_tag(cluster_mean)
            
            self.cluster_profiles[cluster_id] = {
                'name': tribe_tag,
                'features': cluster_mean.tolist(),
                'size': len(cluster_feats)
            }
        
        # LoRA'lara tag ekle
        for lora in valid_loras:
            if lora.id in new_clusters:
                cluster_id = new_clusters[lora.id]
                tribe_tag = self.cluster_profiles[cluster_id]['name']
                
                # LoRA'ya tag ekle
                if not hasattr(lora, 'sieve_tags'):
                    lora.sieve_tags = []
                
                # Yeni tag ekle (duplicate kontrolÃ¼)
                if tribe_tag not in lora.sieve_tags:
                    lora.sieve_tags.append(tribe_tag)
        
        # GÃ¼ncelleme tracking
        self.clusters = new_clusters
        self.population_snapshot = {lora.id: lora for lora in population}
        self.last_update_match = current_match
        
        # Ä°statistikler
        num_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        num_noise = list(labels).count(-1)
        
        if num_clusters > 0:
            print(f"ğŸ•¸ï¸ SIEVE: {num_clusters} kabile tespit edildi ({len(valid_loras)} LoRA, {num_noise} noise)")
    
    def get_tribe_distribution(self, population: List[Any]) -> Dict[str, int]:
        """
        Tribe daÄŸÄ±lÄ±mÄ±nÄ± dÃ¶ndÃ¼r
        
        Returns:
            {tribe_name: count}
        """
        distribution = defaultdict(int)
        
        for lora in population:
            if hasattr(lora, 'sieve_tags') and lora.sieve_tags:
                for tag in lora.sieve_tags:
                    distribution[tag] += 1
        
        return dict(distribution)
    
    def get_lora_tribe(self, lora_id: str) -> Optional[str]:
        """
        Bir LoRA'nÄ±n tribe'ini dÃ¶ndÃ¼r
        
        Returns:
            Tribe name veya None
        """
        if lora_id in self.clusters:
            cluster_id = self.clusters[lora_id]
            if cluster_id in self.cluster_profiles:
                return self.cluster_profiles[cluster_id]['name']
        return None
    
    def get_tribes(self, population: List[Any]) -> Dict[int, List[Any]]:
        """
        PopÃ¼lasyondan kabileleri dÃ¶ndÃ¼r (cluster_id â†’ [lora1, lora2, ...])
        
        Args:
            population: LoRA popÃ¼lasyonu
        
        Returns:
            {cluster_id: [lora1, lora2, ...]} - Kabileler
        """
        tribes = {}
        
        for lora in population:
            if lora.id in self.clusters:
                cluster_id = self.clusters[lora.id]
                if cluster_id not in tribes:
                    tribes[cluster_id] = []
                tribes[cluster_id].append(lora)
        
        # Noise'larÄ± (cluster_id == -1) hariÃ§ tut
        tribes = {k: v for k, v in tribes.items() if k != -1}
        
        return tribes
    
    def clear_history(self, lora_id: str):
        """Bir LoRA'nÄ±n geÃ§miÅŸini temizle (Ã¶lÃ¼m sonrasÄ±)"""
        if lora_id in self.prediction_history:
            del self.prediction_history[lora_id]
        if lora_id in self.error_history:
            del self.error_history[lora_id]
        if lora_id in self.clusters:
            del self.clusters[lora_id]


# Global instance
_global_sieve = None


def get_background_sieve(buffer_size: int = 50, 
                        update_frequency: int = 10) -> BackgroundSieve:
    """Global BackgroundSieve instance"""
    global _global_sieve
    if _global_sieve is None:
        _global_sieve = BackgroundSieve(
            buffer_size=buffer_size,
            update_frequency=update_frequency
        )
    return _global_sieve

