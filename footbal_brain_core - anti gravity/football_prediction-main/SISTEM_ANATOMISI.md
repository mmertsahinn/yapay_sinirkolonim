# ğŸ§¬ SÄ°STEM ANATOMÄ°SÄ° - TABANLIK DÃ–KÃœMAN

**Sistemin 5 ana bileÅŸeninin tam anatomisi.**

SÄ±rasÄ±yla:
1. LoRA SÄ±nÄ±fÄ± (Birey)
2. Evrim Motoru (DoÄŸum/Ã–lÃ¼m/Ã‡iftleÅŸme)
3. Scoreboard (Adalet Sistemi)
4. Meta-LoRA (Kolektif BilinÃ§)
5. Replay Buffer (Kolektif HafÄ±za)

---

## 1ï¸âƒ£ LoRA SINIFI (`lora_adapter.py`)

**Dosya:** `lora_system/lora_adapter.py`

### ğŸ“Œ LoRA NEDÄ°R?

LoRA = **Low-Rank Adaptation**

Bir sinir aÄŸÄ±nÄ±n **aÄŸÄ±rlÄ±klarÄ±nÄ± dondurup**, sadece **kÃ¼Ã§Ã¼k ek matrisler (A, B)** ekleyerek Ã¶ÄŸrenme yapar.

```
W_final = W_frozen + (B @ A) * (alpha / rank)
```

**Avantajlar:**
- Ã‡ok az parametre (rank=16 â†’ Ã§ok kÃ¼Ã§Ã¼k!)
- HÄ±zlÄ± eÄŸitim
- Evrimsel Ã§iftleÅŸme kolay (sadece A, B karÄ±ÅŸtÄ±rÄ±lÄ±r)

---

### ğŸ§± MÄ°MARÄ°

```python
Input (63 boyut)
  â†“
LoRALinear(63 â†’ 128, rank=16)  # fc1
  â†“
ReLU + Dropout(0.1)
  â†“
LoRALinear(128 â†’ 64, rank=16)  # fc2
  â†“
ReLU + Dropout(0.1)
  â†“
LoRALinear(64 â†’ 3, rank=16)    # fc3
  â†“
Softmax
  â†“
Output (3 boyut: HOME, DRAW, AWAY)
```

**Parametreler:**
- Rank: 16 (LoRA matrislerin boyutu)
- Alpha: 16.0 (scaling faktÃ¶rÃ¼)
- Hidden: 128 (gizli katman boyutu)

---

### ğŸ§¬ LoRA'NIN ANATOMÄ°SÄ° (Ã–zellikler)

#### A) TEMEL Ã–ZELLÄ°KLER

```python
self.id              # Benzersiz ID (8 karakter)
self.name            # Ä°sim (Ã¶rn: "LoRA_Gen3_abc123")
self.generation      # Nesil (0, 1, 2, ...)
self.parents         # Anne-Baba ID'leri
self.birth_match     # Hangi maÃ§ta doÄŸdu?
```

#### B) PERFORMANS METRÄ°KLERÄ°

```python
self.match_history     # MaÃ§ geÃ§miÅŸi
self.fitness_history   # Fitness skoru geÃ§miÅŸi (0-1 arasÄ±)
self.specialization    # UzmanlÄ±k (Ã¶rn: "hype_expert")
```

**Fitness HesaplamasÄ±:**

```python
def update_fitness(self, correct: bool, confidence: float):
    if correct:
        fitness = 0.5 + 0.5 * confidence  # 0.5 - 1.0
    else:
        fitness = 0.5 * (1 - confidence)  # 0.0 - 0.5
    
    self.fitness_history.append(fitness)
```

**MantÄ±k:**
- DoÄŸru tahmin â†’ 0.5-1.0 (yÃ¼ksek gÃ¼venle doÄŸru = 1.0)
- YanlÄ±ÅŸ tahmin â†’ 0.0-0.5 (Ã§ok eminken yanÄ±lma = 0.0!)

#### C) SOSYAL Ã–ZELLÄ°KLER

```python
self.pattern_attractions = {}  # Pattern Ã§ekimleri
self.social_bonds = {}         # DiÄŸer LoRA'larla baÄŸlar
self.main_goal = None          # Ana hedef
self.trauma_history = []       # Travma geÃ§miÅŸi
```

#### D) ğŸ­ KÄ°ÅÄ°LÄ°K Ã–ZELLÄ°KLERÄ° (Genetik!)

```python
self.temperament = {
    'independence': 0.3-0.9,        # BaÄŸÄ±msÄ±zlÄ±k
    'social_intelligence': 0.3-0.9, # Sosyal zeka
    'herd_tendency': 0.1-0.8,       # SÃ¼rÃ¼ eÄŸilimi
    'contrarian_score': 0.0-0.7,    # KarÅŸÄ±t gÃ¶rÃ¼ÅŸ
    'confidence_level': 0.4-0.9,    # Ã–zgÃ¼ven
    'risk_appetite': 0.2-0.9,       # Risk iÅŸtahÄ±
    'patience': 0.3-0.9,            # SabÄ±r
    'impulsiveness': 0.1-0.8,       # DÃ¼rtÃ¼sellik
    'stress_tolerance': 0.4-0.9     # Stres toleransÄ±
}
```

**GENETÄ°K AKTARIM:**
- Anne + Baba kiÅŸilikleri karÄ±ÅŸÄ±r (ortalama + Â±%20 mutasyon)
- %5 ÅŸans: Tamamen yeni kiÅŸilik (alien bebek!)

#### E) ğŸ§  KÄ°ÅÄ°SEL HAFIZA (YENÄ°!)

```python
self.personal_memory = {
    'learned_patterns': {},    # Kendi Ã¶ÄŸrenmeleri
    'learning_history': [],    # Ne zaman ne Ã¶ÄŸrendi
    'observed_others': {},     # BaÅŸkalarÄ±ndan ne gÃ¶rdÃ¼
    'adjustments': []          # Kendi deÄŸiÅŸimleri
}
```

Bu, LoRA'nÄ±n **kendi Ã¶ÄŸrenme tarihi**!

#### F) ğŸ€ HAYATTA KALMA

```python
self.lucky_survivals = 0     # KaÃ§ kez ÅŸanslÄ± kurtuldu
self.resurrection_count = 0  # KaÃ§ kez dirildi
self.children_count = 0      # KaÃ§ Ã§ocuk doÄŸurdu
```

---

### ğŸ”„ Ã–NEMLÄ° METODLAR

#### 1) `predict(features, base_proba, device)`

**Ne yapar:** MaÃ§ tahmini yapar.

**Input:**
- `features`: 60 boyutlu Ã¶zellik vektÃ¶rÃ¼
- `base_proba`: Ensemble'dan gelen 3 boyutlu tahmin

**Output:**
- `proba`: 3 boyutlu tahmin (HOME, DRAW, AWAY)

**NasÄ±l:**
```python
# Input: [60 features + 3 base_proba] = 63 boyut
x = concat(features, base_proba)
x = forward(x)  # AÄŸdan geÃ§ir
return softmax(x)  # 0-1 arasÄ± normalize
```

#### 2) `clone()`

**Ne yapar:** Bu LoRA'nÄ±n kopyasÄ±nÄ± oluÅŸturur.

**KullanÄ±m:** Evrimde mutasyon iÃ§in.

```python
new_lora = lora.clone()
new_lora.temperament = lora.temperament.copy()  # KiÅŸilik kopyalanÄ±r!
```

#### 3) `get_recent_fitness(window=50)`

**Ne yapar:** Son N maÃ§taki ortalama fitness.

```python
recent = self.fitness_history[-50:]
return np.mean(recent)
```

#### 4) `get_all_lora_params()` / `set_all_lora_params()`

**Ne yapar:** Ã‡iftleÅŸme ve klonlama iÃ§in LoRA parametrelerini al/kur.

```python
params = lora.get_all_lora_params()
# params = {
#     'fc1': {'lora_A': tensor, 'lora_B': tensor},
#     'fc2': {...},
#     'fc3': {...}
# }

child.set_all_lora_params(params)
```

---

### ğŸ“ ONLINELoRALEARNER (Ã–ÄŸrenme Wrapper)

**Ne yapar:** Her maÃ§tan sonra LoRA'yÄ± gÃ¼nceller (gradient descent).

```python
learner = OnlineLoRALearner(lora, learning_rate=0.0001)
loss = learner.learn_batch(batch)
```

**NasÄ±l:**
- Sadece LoRA parametrelerini (A, B) optimize eder
- Ana aÄŸÄ±rlÄ±klar DONUK kalÄ±r
- Adam optimizer
- CrossEntropyLoss

---

## 2ï¸âƒ£ EVRÄ°M MOTORU (`chaos_evolution.py`)

**Dosya:** `lora_system/chaos_evolution.py`

### ğŸ“Œ EVRÄ°M MOTORU NEDÄ°R?

PopÃ¼lasyonun **doÄŸal seleksiyon** ile evrimini yÃ¶neten motor.

**3 Ana SÃ¼reÃ§:**
1. **Ã–lÃ¼m** (Fitness < threshold â†’ Ã¶lÃ¼m + ÅŸanslÄ± kurtuluÅŸ)
2. **Ãœreme** (Fitness > threshold â†’ partner bul â†’ Ã§iftleÅŸ)
3. **Spontane DoÄŸum** (Rastgele alien LoRA doÄŸar!)

---

### âš™ï¸ PARAMETReler (Config)

```yaml
population:
  min_population: 5        # Minimum popÃ¼lasyon (yoksa diriltme!)
  max_population: null     # Ãœst limit YOK! (doÄŸa dengeyi kurar)

death:
  threshold: 0.05          # Fitness < 0.05 â†’ Ã¶lÃ¼m riski
  lucky_survival_chance: 0.50  # %50 ÅŸanslÄ± kurtuluÅŸ!

reproduction:
  fitness_threshold: 0.60  # Fitness > 0.60 â†’ Ã¼reme hakkÄ±
  chance_per_match: 0.06   # Her maÃ§ta %6 Ã¼reme ÅŸansÄ±
  
  partner_selection:
    random: 0.30           # %30 rastgele partner (KAOS!)
    strongest: 0.30        # %30 en gÃ¼Ã§lÃ¼
    weakest: 0.20          # %20 en zayÄ±f (sÃ¼rpriz!)
    complementary: 0.20    # %20 tamamlayÄ±cÄ± (farklÄ± Ã¶zellik)

noise:
  crossover:
    base_noise_max: 0.3    # Ã‡iftleÅŸmede gÃ¼rÃ¼ltÃ¼ max %30
    mega_noise_chance: 0.10  # %10 MEGA gÃ¼rÃ¼ltÃ¼!
  
  mutation:
    param_mutation_chance: 0.15  # %15 mutasyon
    shock_mutation_chance: 0.05  # %5 ÅŸok mutasyon!
  
  spontaneous_birth:
    chance_per_match: 0.04  # %4 spontane doÄŸum (alien!)
```

---

### ğŸ’€ Ã–LÃœM SÄ°STEMÄ°

#### Ã–lÃ¼m Kriterleri:

```python
def evolution_step():
    for lora in population:
        fitness = lora.get_recent_fitness()
        
        if fitness < self.death_threshold:  # 0.05
            # Ã–LÃœM RÄ°SKÄ°!
            
            if random() < self.lucky_survival_chance:  # 0.50
                # ğŸ€ ÅANSLI KURTULUÅ!
                lora.lucky_survivals += 1
                survivors.append(lora)
            else:
                # ğŸ’€ Ã–LÃœM!
                death_reason = _determine_death_reason(lora, fitness)
                # Ã–lÃ¼m loglanÄ±r
```

#### Ã–lÃ¼m Sebepleri:

```python
def _determine_death_reason(lora, fitness):
    if fitness < 0.02:
        return "Kritik dÃ¼ÅŸÃ¼k fitness"
    
    if hasattr(lora, 'goalless_death_risk') and risk > 0.5:
        return "Hedefsizlik sÃ¼rÃ¼klenmesi"
    
    if len(lora.trauma_history) > 5:
        return "AÅŸÄ±rÄ± travma"
    
    return "DÃ¼ÅŸÃ¼k performans"
```

---

### ğŸ‘¶ ÃœREME SÄ°STEMÄ° (DOÄAL BAÄ BAZLI!)

#### DoÄŸal Ãœreme ÅansÄ±:

```python
def _calculate_natural_reproduction_chance(lora, population_size, alarm_info):
    # 1) SOSYAL BAÄ (40%)
    if lora.social_bonds:
        max_bond = max(lora.social_bonds.values())
        bond_score = max_bond * 0.40
    else:
        bond_score = 0.10  # BaÄŸsÄ±z = dÃ¼ÅŸÃ¼k ÅŸans
    
    # 2) FITNESS (30%)
    fitness_score = lora.get_recent_fitness() * 0.30
    
    # 3) HIRSLIK (15%)
    ambition_score = lora.temperament['ambition'] * 0.15
    
    # 4) NÃœFUS FAKTÃ–RÃœ (15%) - DÃ¼nya gibi artar!
    # 50 LoRA: 0.50, 100: 0.60, 200: 0.75, 400: 0.95
    population_factor = 0.50 + min(population_size / 1000, 0.45)
    population_score = population_factor * 0.15
    
    # TOPLAM
    natural_chance = bond_score + fitness_score + ambition_score + population_score
    
    # Alarm varsa (soy azalÄ±rsa) alarm_chance ile karÅŸÄ±laÅŸtÄ±r
    if alarm_info:
        alarm_chance = base_chance * alarm_info['reproduction_multiplier']
        final_chance = max(natural_chance, alarm_chance)
    
    return min(0.95, final_chance)  # Max %95
```

**MantÄ±k:**
- GÃ¼Ã§lÃ¼ sosyal baÄŸ â†’ Daha Ã§ok Ã§ocuk!
- SaÄŸlÄ±klÄ± â†’ Daha Ã§ok Ã§ocuk!
- HÄ±rslÄ± â†’ Daha Ã§ok Ã§ocuk!
- KalabalÄ±k dÃ¼nya â†’ DoÄŸum oranÄ± artar! (gerÃ§ek dÃ¼nya gibi!)

#### Partner SeÃ§imi:

```python
def select_partner(lora):
    rand = random()
    
    # %30: Tamamen rastgele (KAOS!)
    if rand < 0.30:
        return random.choice(others)
    
    # %30: En gÃ¼Ã§lÃ¼ (klasik evrim)
    elif rand < 0.60:
        return max(others, key=lambda x: x.get_recent_fitness())
    
    # %20: En zayÄ±f (sÃ¼rpriz potansiyeli!)
    elif rand < 0.80:
        return min(others, key=lambda x: x.get_recent_fitness())
    
    # %20: TamamlayÄ±cÄ± (farklÄ± Ã¶zellik)
    else:
        return _find_complementary(lora, others)
```

**TamamlayÄ±cÄ± Partner:**
- En FARKLI parametre yapÄ±sÄ±na sahip LoRA seÃ§ilir.
- AmaÃ§: Ã‡eÅŸitliliÄŸi artÄ±rmak!

---

### ğŸŒªï¸ KAOTÄ°K Ã‡Ä°FTLEÅME (Crossover)

```python
def chaotic_crossover(parent1, parent2):
    child = LoRAAdapter()
    
    for layer in ['fc1', 'fc2', 'fc3']:
        for matrix in ['lora_A', 'lora_B']:
            # Her parametrede FARKLI gÃ¼rÃ¼ltÃ¼!
            noise_level = random(0, 0.3)  # %0-%30 gÃ¼rÃ¼ltÃ¼
            
            # Anne veya baba?
            if random() < 0.5:
                base = parent1.params[layer][matrix]
            else:
                base = parent2.params[layer][matrix]
            
            # GÃ¼rÃ¼ltÃ¼ ekle
            result = base + randn_like(base) * noise_level
            
            # %10: MEGA GÃœRÃœLTÃœ!
            if random() < 0.10:
                avg = (parent1.params + parent2.params) / 2
                mega_noise = randn_like(avg) * 0.5
                result = avg + mega_noise
            
            child.params[layer][matrix] = result
    
    # ğŸ­ KÄ°ÅÄ°LÄ°K GENETÄ°ÄÄ°
    child.temperament = _inherit_temperament(parent1, parent2)
    
    # Anne-Baba Ã§ocuk sayÄ±sÄ±nÄ± artÄ±r
    parent1.children_count += 1
    parent2.children_count += 1
    
    return child
```

**KiÅŸilik KalÄ±tÄ±mÄ±:**

```python
def _inherit_temperament(parent1, parent2):
    # %5 ÅŸans: TAM YENÄ° KÄ°ÅÄ°LÄ°K (alien bebek!)
    if random() < 0.05:
        return random_temperament()
    
    # Anne + Baba ortalamasÄ± + Â±%20 mutasyon
    child_temp = {}
    for trait in temperament.keys():
        p1_val = parent1.temperament[trait]
        p2_val = parent2.temperament[trait]
        
        avg = (p1_val + p2_val) / 2
        mutation = random(-0.2, 0.2)
        final_val = clamp(avg + mutation, 0, 1)
        
        child_temp[trait] = final_val
    
    return child_temp
```

---

### ğŸ‘½ SPONTANE DOÄUM (Alien LoRA)

```python
def spawn_random_lora():
    alien = LoRAAdapter()
    alien.name = f"LoRA_Alien_{id}"
    alien.generation = 0
    alien.parents = []
    
    # ğŸ‘½ EKSTREM KÄ°ÅÄ°LÄ°K!
    alien.temperament = {
        'independence': 0.7-1.0,        # Ã‡OK baÄŸÄ±msÄ±z!
        'social_intelligence': 0.0-0.5, # Sosyal zeka dÃ¼ÅŸÃ¼k
        'herd_tendency': 0.0-0.3,       # SÃ¼rÃ¼ye uymaz!
        'contrarian_score': 0.5-1.0,    # Ã‡OK karÅŸÄ±t!
        'confidence_level': 0.6-1.0,    # AÅŸÄ±rÄ± Ã¶zgÃ¼venli
        'risk_appetite': 0.7-1.0,       # Risk sever!
        'patience': 0.1-0.5,            # SabÄ±rsÄ±z
        'impulsiveness': 0.6-1.0,       # DÃ¼rtÃ¼sel
        'stress_tolerance': 0.3-0.8
    }
    
    return alien
```

**Alien LoRA Ã–zellikleri:**
- HiÃ§ ebeveyn yok!
- Ekstrem kiÅŸilik (baÄŸÄ±msÄ±z, karÅŸÄ±t, risk sever!)
- SÄ±fÄ±r nesil (Gen0)
- SÃ¼rpriz potansiyeli yÃ¼ksek!

---

### ğŸ”„ EVRÄ°M ADIMI (Her MaÃ§ SonrasÄ±)

```python
def post_match_update(alarm_info=None):
    match_count += 1
    
    # 1) Ã–LÃœMLER (fitness < threshold)
    # 2) ÃœREMELER (fitness > threshold + doÄŸal ÅŸans)
    # 3) SPONTANE DOÄUM (%4 ÅŸans)
    # 4) SOY TÃœKENMESÄ° KONTROLÃœ (population == 0 â†’ diriltme!)
    
    return events  # birth, death, lucky_survival, spontaneous_birth
```

---

## 3ï¸âƒ£ SCOREBOARD FORMÃœLÃœ (`advanced_score_calculator.py`)

**Dosya:** `lora_system/advanced_score_calculator.py`

### ğŸ“Œ SCOREBOARD NEDÄ°R?

LoRA'larÄ± **adil bir ÅŸekilde sÄ±ralamak** iÃ§in kullanÄ±lan geliÅŸmiÅŸ formÃ¼l.

**AmaÃ§:**
- GenÃ§ yetenekler yaÅŸlÄ±larÄ± geÃ§ebilsin!
- Trend Ã¶nemli (yÃ¼kseliyor mu?)
- Ä°stikrar Ã¶dÃ¼llendirilsin
- YaÅŸa gÃ¶re normalize (genÃ§ = daha az beklenti)

---

### ğŸ§® FORMÃœL

```
ADVANCED_SCORE = 
  (Weighted_Recent Ã— 0.30) +      # Son performans (aÄŸÄ±rlÄ±klÄ±)
  (Age_Normalized Ã— 0.25) +       # YaÅŸa gÃ¶re normalize baÅŸarÄ±
  (Peak_Performance Ã— 0.20) +     # En iyi dÃ¶nem
  (Momentum Ã— 0.15) +             # Trend (yÃ¼kseliyor mu?)
  (Consistency Ã— 0.10)            # Ä°stikrar
```

**Toplam: 1.00** (0-1 arasÄ± normalize)

---

### ğŸ“Š BÄ°LEÅENLER

#### 1) WEIGHTED RECENT (30%)

**Ne:** Son performans (exponential weighted average)

**NasÄ±l:**
```python
history = lora.fitness_history[-50:]  # Son 50 maÃ§

# Exponential aÄŸÄ±rlÄ±klar
weights = []
for i in range(len(history)):
    weight = exp(i / len(history))  # Son maÃ§ = en yÃ¼ksek aÄŸÄ±rlÄ±k
    weights.append(weight)

weights = weights / sum(weights)  # Normalize

weighted_avg = dot(history, weights)
```

**MantÄ±k:** Son maÃ§lar daha Ã¶nemli!

---

#### 2) AGE-NORMALIZED SUCCESS (25%)

**Ne:** YaÅŸa gÃ¶re normalize baÅŸarÄ±

**NasÄ±l:**
```python
success_rate = count(fitness > 0.5) / len(history)
age = match_count - lora.birth_match

# Beklenen baÅŸarÄ± (yaÅŸa gÃ¶re artar!)
# 0-50 maÃ§: %50 beklenir
# 50-100: %55
# 100-200: %60
# 200+: %65
expected = 0.50 + min(age / 400, 0.15)  # Max +15%

# Normalize: GerÃ§ek / Beklenen
normalized = success_rate / expected
```

**MantÄ±k:**
- GenÃ§ LoRA: %60 baÅŸarÄ± = 0.90 skor (**Ã‡OK Ä°YÄ°!**)
- YaÅŸlÄ± LoRA: %60 baÅŸarÄ± = 0.70 skor (**ORTA**)

**GenÃ§ yetenekler avantajlÄ±!**

---

#### 3) PEAK PERFORMANCE (20%)

**Ne:** En iyi 20 maÃ§lÄ±k dÃ¶nem performansÄ±

**NasÄ±l:**
```python
# 20 maÃ§lÄ±k sliding window
best_avg = 0.0
for i in range(len(history) - 19):
    window = history[i:i+20]
    window_avg = mean(window)
    best_avg = max(best_avg, window_avg)

return best_avg
```

**MantÄ±k:** Potansiyeli gÃ¶sterir! (Bir dÃ¶nem ne kadar iyi olmuÅŸ?)

---

#### 4) MOMENTUM (15%)

**Ne:** Trend (yÃ¼kseliyor mu dÃ¼ÅŸÃ¼yor mu?)

**NasÄ±l:**
```python
# Son 20 maÃ§ vs Ã–nceki 20 maÃ§
recent_20 = history[-20:]
previous_20 = history[-40:-20]

recent_avg = mean(recent_20)
previous_avg = mean(previous_20)

momentum_ratio = recent_avg / previous_avg

# 0.5-1.5 arasÄ± â†’ 0-1 arasÄ± normalize
# 0.5 â†’ dÃ¼ÅŸÃ¼ÅŸ (0.0)
# 1.0 â†’ sabit (0.5)
# 1.5 â†’ artÄ±ÅŸ (1.0)
normalized_momentum = (momentum_ratio - 0.5) / 1.0
normalized_momentum = clamp(normalized_momentum + 0.5, 0, 1)
```

**MantÄ±k:** YÃ¼kseliÅŸ trendi Ã¶dÃ¼llendirilir!

---

#### 5) CONSISTENCY (10%)

**Ne:** Ä°stikrar (Variance ne kadar dÃ¼ÅŸÃ¼k?)

**NasÄ±l:**
```python
history = fitness_history[-50:]  # Son 50 maÃ§

mean = sum(history) / len(history)
variance = sum((f - mean)^2 for f in history) / len(history)
std = sqrt(variance)

# DÃ¼ÅŸÃ¼k std = yÃ¼ksek consistency
# std: 0.0 â†’ 1.0, 0.3+ â†’ 0.0
consistency = max(0, 1.0 - (std / 0.3))
```

**MantÄ±k:** Ä°stikrarlÄ± LoRA > KararsÄ±z LoRA

---

### ğŸ¯ Ã–RNEK HESAPLAMA

**LoRA_Einstein:**
- Fitness history: 50 maÃ§, avg=0.75
- YaÅŸ: 120 maÃ§
- Son 20 maÃ§: 0.80 avg
- Ã–nceki 20 maÃ§: 0.70 avg
- Peak 20 maÃ§: 0.85
- Std: 0.12

**Hesaplama:**

```
Weighted Recent: 0.78 * 0.30 = 0.234
Age Normalized: (0.75 / 0.59) * 0.25 = 0.318
  (expected = 0.50 + 120/400*0.15 = 0.545 â‰ˆ 0.59)
Peak: 0.85 * 0.20 = 0.170
Momentum: ((0.80/0.70 - 0.5) / 1.0 + 0.5) * 0.15 = 0.105
  (momentum_ratio = 1.14 â†’ normalized = 0.64)
Consistency: (1 - 0.12/0.3) * 0.10 = 0.060

TOPLAM = 0.234 + 0.318 + 0.170 + 0.105 + 0.060 = 0.887
```

**Einstein'Ä±n Advanced Score: 0.887 / 1.00 (%88.7)**

---

## 4ï¸âƒ£ META-LoRA (`meta_lora.py`)

**Dosya:** `lora_system/meta_lora.py`

### ğŸ“Œ META-LoRA NEDÄ°R?

**"Hangi LoRA'yÄ± dinleyelim?"** kararÄ±nÄ± veren Ã¼st akÄ±l.

**Mekanizma:** Attention (Dikkat)

**Analoji:**
- LoRA'lar = Uzmanlar
- Meta-LoRA = ModeratÃ¶r
- Her maÃ§ = FarklÄ± uzmanlar dinlenir!

---

### ğŸ§  ATTENTION MEKANÄ°ZMASI

```
MaÃ§ Ã–zellikleri (63 boyut)
  â†“
Query Network
  â†“
Query VektÃ¶rÃ¼ (16 boyut)
  â†“
Her LoRA â†’ Key VektÃ¶rÃ¼ (16 boyut)
  â†“
Attention Scores = Query @ Keys^T
  â†“
Softmax â†’ Attention Weights (0-1 arasÄ±, toplam=1)
  â†“
Weighted Average (LoRA tahminlerini aÄŸÄ±rlÄ±klandÄ±r)
  â†“
Final Prediction
```

---

### ğŸ”‘ KEY VEKTÃ–RÃœ (LoRA'nÄ±n Ä°mzasÄ±)

```python
def get_lora_key(lora):
    params = lora.get_all_lora_params()
    
    features = []
    for layer in ['fc1', 'fc2', 'fc3']:
        for matrix in ['lora_A', 'lora_B']:
            # Ä°statistikler: mean, std
            features.extend([
                params[layer][matrix].mean(),
                params[layer][matrix].std()
            ])
    
    # 12 Ã¶zellik â†’ 16 boyuta pad
    key = tensor(features[:16])
    return key
```

**Key = LoRA'nÄ±n imzasÄ±** (parametrelerinden Ã§Ä±karÄ±lÄ±r)

---

### âš–ï¸ ATTENTION WEIGHTS HESAPLAMA

```python
def forward(match_features, lora_population):
    # Query: MaÃ§ Ã¶zelliklerinden
    query = query_net(match_features)  # (1, 16)
    
    # Keys: Her LoRA'dan
    keys = [get_lora_key(lora) for lora in lora_population]
    keys = stack(keys)  # (num_loras, 16)
    
    # Attention scores
    scores = query @ keys.T  # (1, num_loras)
    
    # Softmax
    attention_weights = softmax(scores)  # Toplam = 1.0
    
    return attention_weights
```

---

### ğŸ¯ AGGREGATE PREDICTIONS (Nihai Tahmin)

```python
def aggregate_predictions(match_features, base_proba, lora_population):
    # 1) Attention weights hesapla
    attention_weights = forward(match_features, lora_population)
    
    # 2) Her LoRA'dan tahmin al
    individual_probas = []
    for lora in lora_population:
        lora_proba = lora.predict(match_features, base_proba)
        individual_probas.append(lora_proba)
    
    # 3) Weighted average
    aggregated_proba = sum(
        individual_probas * attention_weights[:, None],
        axis=0
    )
    
    # 4) Normalize
    aggregated_proba /= aggregated_proba.sum()
    
    return aggregated_proba
```

---

### ğŸ“Š Ã–RNEK

**MaÃ§:** Galatasaray - FenerbahÃ§e

**PopÃ¼lasyon:**
- LoRA_Hype (derbi uzmanÄ±): Fitness=0.80
- LoRA_Odds (oran uzmanÄ±): Fitness=0.70
- LoRA_Alien (kaotik): Fitness=0.50

**Attention Weights:**
```
LoRA_Hype: 0.60   (Derbi maÃ§Ä± â†’ Hype uzmanÄ± Ã¶ne Ã§Ä±kÄ±yor!)
LoRA_Odds: 0.30
LoRA_Alien: 0.10
```

**Individual Predictions:**
```
LoRA_Hype:  [0.30, 0.20, 0.50]  (AWAY aÄŸÄ±rlÄ±klÄ±)
LoRA_Odds:  [0.50, 0.30, 0.20]  (HOME aÄŸÄ±rlÄ±klÄ±)
LoRA_Alien: [0.10, 0.10, 0.80]  (AWAY Ã§ok aÄŸÄ±rlÄ±klÄ±!)
```

**Aggregated:**
```
Final = 0.60*[0.30, 0.20, 0.50] + 0.30*[0.50, 0.30, 0.20] + 0.10*[0.10, 0.10, 0.80]
      = [0.18, 0.12, 0.30] + [0.15, 0.09, 0.06] + [0.01, 0.01, 0.08]
      = [0.34, 0.22, 0.44]
```

**Final Prediction: AWAY (44%)**

**Meta-LoRA derbi uzmanÄ±nÄ± dinledi!**

---

### ğŸ†š SimpleMetaLoRA (Alternatif)

**BasitleÅŸtirilmiÅŸ versiyon:**
- Attention yok!
- Sadece fitness bazlÄ± aÄŸÄ±rlÄ±klandÄ±rma

```python
def aggregate_predictions(match_features, base_proba, lora_population):
    # Her LoRA'dan tahmin + fitness al
    probas = []
    fitnesses = []
    
    for lora in lora_population:
        probas.append(lora.predict(match_features, base_proba))
        fitnesses.append(lora.get_recent_fitness())
    
    # Fitness'i aÄŸÄ±rlÄ±k olarak kullan (softmax)
    weights = exp(fitnesses * 5)
    weights /= weights.sum()
    
    # Weighted average
    aggregated = sum(probas * weights[:, None], axis=0)
    
    return aggregated
```

**Basit ama etkili!**

---

## 5ï¸âƒ£ REPLAY BUFFER (`replay_buffer.py`)

**Dosya:** `lora_system/replay_buffer.py`

### ğŸ“Œ REPLAY BUFFER NEDÄ°R?

**Ã–nemli maÃ§larÄ± saklar** ve online Ã¶ÄŸrenme iÃ§in kullanÄ±r.

**AmaÃ§:**
- Modelin yanÄ±ldÄ±ÄŸÄ± maÃ§larÄ± hatÄ±rla!
- SÃ¼rpriz skorlarÄ± hatÄ±rla!
- YÃ¼ksek hype maÃ§larÄ± hatÄ±rla!

---

### ğŸ“¦ BUFFER YAPISI

```python
storage = [
    {
        'features': np.array (60,),
        'base_proba': np.array (3,),
        'lora_proba': np.array (3,),
        'actual_class_idx': int,
        'actual_result': str,
        'loss': float,
        'surprise': float,  # 1 - p(actual)
        'hype': float,      # total_tweets
        'goal_diff': int,
        'match_date': str,
        'home_team': str,
        'away_team': str,
        'league': str,
        'predicted_class': str,
        'correct': bool,
        'importance': float  # 0-1 arasÄ±
    },
    ...
]
```

**Max size:** 1000 maÃ§

---

### ğŸ¯ IMPORTANCE (Ã–nem Skoru)

**Ne kadar Ã¶nemli?**

```python
def _calculate_importance(example):
    importance = 0.0
    
    # 1) LOSS (30%)
    loss = example['loss']
    importance += min(loss, 2.0) * 0.3  # Max 0.6 katkÄ±
    
    # 2) SURPRISE (30%)
    surprise = example['surprise']  # 1 - p(actual)
    importance += surprise * 0.3
    
    # 3) GOL FARKI (30%)
    goal_diff = abs(example['goal_diff'])
    if goal_diff >= 5:
        importance += 0.3  # 5+ fark = Ã‡OK Ã¶nemli!
    elif goal_diff >= 3:
        importance += 0.2
    elif goal_diff >= 2:
        importance += 0.1
    
    # 4) HYPE (10%)
    hype = example['hype']
    normalized_hype = min(hype / 50000, 1.0)
    importance += normalized_hype * 0.2
    
    return importance
```

**Toplam: 0-1.0 arasÄ±**

**YÃ¼ksek Ã¶nem:**
- Model Ã§ok yanÄ±ldÄ± (yÃ¼ksek loss)
- Beklenmedik sonuÃ§ (yÃ¼ksek surprise)
- AÅŸÄ±rÄ± skor farkÄ± (7-0, 5-1, vs.)
- Ã‡ok hype'lÄ± maÃ§ (derbi, vs.)

---

### ğŸ² SAMPLING (Ã–rnekleme)

#### 1) WEIGHTED SAMPLING (AÄŸÄ±rlÄ±klÄ±)

```python
def sample(batch_size=16):
    # Ã–nem skorlarÄ±nÄ± aÄŸÄ±rlÄ±k olarak kullan
    importances = [ex['importance'] for ex in storage]
    probs = importances / sum(importances)
    
    # AÄŸÄ±rlÄ±klÄ± Ã¶rnekleme
    indices = np.random.choice(
        len(storage),
        size=batch_size,
        replace=False,
        p=probs
    )
    
    return [storage[i] for i in indices]
```

**Ã–nemli maÃ§lar daha sÄ±k Ã¶rneklenir!**

#### 2) UNIFORM SAMPLING (EÅŸit)

```python
def sample_uniform(batch_size=16):
    return random.sample(storage, batch_size)
```

---

### ğŸ—‘ï¸ PRUNING (Temizleme)

**Buffer dolarsa:**

```python
def _prune():
    # Importance'a gÃ¶re sÄ±rala
    storage.sort(key=lambda x: x['importance'], reverse=True)
    
    # En Ã¶nemli max_size kadarÄ±nÄ± tut
    storage = storage[:max_size]
```

**En az Ã¶nemliler atÄ±lÄ±r!**

---

### ğŸ’¾ KAYDETME / YÃœKLEME

```python
def save(filepath):
    joblib.dump({
        'storage': storage,
        'max_size': max_size,
        'total_added': total_added,
        'total_pruned': total_pruned
    }, filepath)

def load(filepath):
    data = joblib.load(filepath)
    storage = data['storage']
    # ...
```

---

### ğŸ” FILTERING (Filtreleme)

```python
def filter_by_criteria(**criteria):
    # Ã–rnek: goal_diff=5, correct=False
    results = []
    
    for ex in storage:
        match = True
        for key, value in criteria.items():
            if ex[key] != value:
                match = False
                break
        
        if match:
            results.append(ex)
    
    return results
```

**Ã–rnek kullanÄ±m:**

```python
# 5 gol farkla yanlÄ±ÅŸ tahmin edilen maÃ§lar
buffer.filter_by_criteria(goal_diff=5, correct=False)

# Derbi maÃ§larÄ±
buffer.filter_by_criteria(league='SÃ¼per Lig', hype_threshold=50000)
```

---

### ğŸ“Š Ä°STATÄ°STÄ°KLER

```python
def get_stats():
    return {
        'size': len(storage),
        'max_size': max_size,
        'total_added': total_added,
        'total_pruned': total_pruned,
        'avg_importance': mean(importances),
        'max_importance': max(importances),
        'avg_loss': mean(losses),
        'avg_surprise': mean(surprises),
        'high_importance_count': count(importance > 0.7)
    }
```

---

## ğŸ¯ Ã–ZET: 5 BÄ°LEÅEN VE ROLLERI

| BileÅŸen | Rol | Analoji |
|---------|-----|---------|
| **LoRA** | Bireysel uzman, tahmin yapar | Ä°nsan |
| **Evrim Motoru** | DoÄŸal seleksiyon, Ã¼reme, Ã¶lÃ¼m | DoÄŸa |
| **Scoreboard** | Adil sÄ±ralama, genÃ§ yetenek tespiti | Hakem |
| **Meta-LoRA** | UzmanlarÄ± aÄŸÄ±rlÄ±klandÄ±r, en iyiyi seÃ§ | ModeratÃ¶r |
| **Replay Buffer** | Ã–nemli maÃ§larÄ± hatÄ±rla, Ã¶ÄŸren | HafÄ±za |

---

## â“ KRITIK SORULAR

### 1) LoRA hakkÄ±nda:

**Q:** LoRA neden bu kadar kÃ¼Ã§Ã¼k?  
**A:** Ã‡Ã¼nkÃ¼ rank=16! Ana aÄŸÄ±rlÄ±klar donuk, sadece 2 kÃ¼Ã§Ã¼k matris (A, B) eÄŸitiliyor. HÄ±zlÄ± + Az hafÄ±za.

**Q:** KiÅŸilik genetik olarak geÃ§iyor, ama nasÄ±l kullanÄ±lÄ±yor?  
**A:** Åu an **Collective Memory** yorumlamasÄ±nda! BaÄŸÄ±msÄ±z LoRA baÅŸkalarÄ±nÄ± az dinler, Sosyal Zeki Ã§ok dinler!

**Q:** Personal memory tam olarak ne iÅŸe yarar?  
**A:** Her LoRA kendi Ã¶ÄŸrenme tarihini tutar. BaÅŸkalarÄ± bu Ã¶ÄŸrenmeyi gÃ¶rebilir ve kendi mizacÄ±na gÃ¶re yorumlayabilir!

---

### 2) Evrim hakkÄ±nda:

**Q:** Neden %50 ÅŸanslÄ± kurtuluÅŸ?  
**A:** Ã‡Ã¼nkÃ¼ dÃ¼ÅŸÃ¼k fitness = kÃ¶tÃ¼ ÅŸans + kÃ¶tÃ¼ performans karÄ±ÅŸÄ±mÄ± olabilir. %50 ÅŸans veririz, belki dÃ¼zelir!

**Q:** Alien LoRA neden Ã¶nemli?  
**A:** Ã‡eÅŸitlilik! EÄŸer tÃ¼m LoRA'lar aynÄ± tip kiÅŸiliÄŸe sahipse, alien LoRA farklÄ± bakÄ±ÅŸ aÃ§Ä±sÄ± getirir.

**Q:** Partner seÃ§imi neden %30 rastgele?  
**A:** KAOS! Bazen en gÃ¼Ã§lÃ¼ + en zayÄ±f = sÃ¼per Ã§ocuk Ã§Ä±kabilir! Rastgelelik sÃ¼rprizlere kapÄ± aÃ§ar.

---

### 3) Scoreboard hakkÄ±nda:

**Q:** Neden yaÅŸ normalize ediliyor?  
**A:** GenÃ§ LoRA'lara ÅŸans vermek iÃ§in! Yoksa yaÅŸlÄ± LoRA'lar hep Ã¼stte olur, genÃ§ yetenekler hiÃ§ yÃ¼kselemez.

**Q:** Momentum neden %15?  
**A:** Trend Ã¶nemli ama yeterince uzun veri gerektirir (40 maÃ§). Bu yÃ¼zden aÄŸÄ±rlÄ±ÄŸÄ± dÃ¼ÅŸÃ¼k.

**Q:** Ä°stikrar neden sadece %10?  
**A:** Ã‡Ã¼nkÃ¼ istikrar Ã¶nemli ama Ã§ok Ã¶dÃ¼llendirirsek riskten kaÃ§Ä±nÄ±rlar. Risk almak da gerekiyor!

---

### 4) Meta-LoRA hakkÄ±nda:

**Q:** Attention vs Simple Meta, hangisi daha iyi?  
**A:** Attention daha sofistike (maÃ§ Ã¶zelliklerine gÃ¶re dinamik). Simple daha basit (sadece fitness). Ä°kisi de iyi, Attention hafif daha iyi.

**Q:** Attention weights kaÃ§ LoRA'ya daÄŸÄ±lÄ±r?  
**A:** Hepsine! Ama genelde top 3-5 LoRA %70-80 aÄŸÄ±rlÄ±ÄŸÄ± alÄ±r.

**Q:** Meta-LoRA eÄŸitiliyor mu?  
**A:** **HAYIR!** Åu an statik. Gelecekte eÄŸitilebilir (meta-learning).

---

### 5) Replay Buffer hakkÄ±nda:

**Q:** 1000 maÃ§ yeterli mi?  
**A:** Åu an yeterli. Gerekirse 2000-5000'e Ã§Ä±karÄ±labilir.

**Q:** Buffer'dan ne sÄ±klÄ±kla Ã¶rnekleniyor?  
**A:** Her maÃ§ta! Yeni maÃ§ + buffer'dan 16 Ã¶rnek = toplam 17 Ã¶rnek ile LoRA Ã¶ÄŸrenir.

**Q:** Buffer'Ä± manuel olarak dÃ¼zenleyebilir miyiz?  
**A:** EVET! `add_user_selected_matches()` ile Ã¶zel maÃ§lar eklenebilir (Ã¶rn: ani deÄŸiÅŸiklikler, Ã¶zel durumlar).

---

## ğŸš€ GELECEK GELÄ°ÅTÄ°RMELER

1. **Meta-LoRA EÄŸitimi:** Attention weights Ã¶ÄŸrenilir hale gelebilir.
2. **Buffer Intelligence:** KullanÄ±cÄ± buffer'a "Turning Point" maÃ§larÄ± ekleyebilir.
3. **LoRA Self-Awareness:** LoRA kendi wallet'Ä±nÄ± okuyup kendini optimize edebilir (ÅŸu an var, daha da geliÅŸtirilecek!).
4. **AÅŸk & Evlilik Sistemi:** Sosyal baÄŸ = %100 â†’ evlilik!
5. **AI Psikolog Raporu:** LoRA'larÄ±n psikolojik durumu analiz edilir.

---

## ğŸ“š KAYNAKLAR

- **LoRA Paper:** "LoRA: Low-Rank Adaptation of Large Language Models" (Hu et al., 2021)
- **Attention:** "Attention Is All You Need" (Vaswani et al., 2017)
- **Replay Buffer:** "Experience Replay in Deep Reinforcement Learning" (Mnih et al., 2015)
- **Genetic Algorithms:** "Genetic Algorithms in Search, Optimization, and Machine Learning" (Goldberg, 1989)

---

**ğŸ‰ ANATOMÄ° TAMAM!**

Åimdi sistemin her hÃ¼cresini biliyorsun!

**Soru varsa sor, kod deÄŸiÅŸikliÄŸi istersen sÃ¶yle!** ğŸš€

