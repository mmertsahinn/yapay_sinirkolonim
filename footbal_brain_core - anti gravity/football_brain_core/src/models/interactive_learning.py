"""
EtkileÅŸimli Ã–ÄŸrenme ve Evrim MekanizmasÄ±
- Model yanlÄ±ÅŸ tahmin yaptÄ±ÄŸÄ±nda nedenini dÃ¼ÅŸÃ¼nÃ¼r
- LLM ile yorum yapar
- MantÄ±klÄ± sebep bulamazsa kullanÄ±cÄ±ya sorar
- KullanÄ±cÄ±yla karÅŸÄ±lÄ±klÄ± fikir alÄ±ÅŸveriÅŸi yapar
- SÃ¼rekli birlikte evrilir
"""
from typing import Dict, List, Any, Optional
import logging
import json
from datetime import datetime

from football_brain_core.src.explanations.llm_client import LLMClient
from football_brain_core.src.models.error_analyzer import ErrorAnalyzer
from football_brain_core.src.db.connection import get_session
from football_brain_core.src.db.repositories import (
    MatchRepository, TeamRepository, ResultRepository, MarketRepository
)
from football_brain_core.src.db.schema import Explanation
from football_brain_core.src.features.market_targets import MarketType

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class InteractiveLearning:
    """
    Model ile kullanÄ±cÄ± arasÄ±nda etkileÅŸimli Ã¶ÄŸrenme mekanizmasÄ±.
    HatalarÄ± analiz eder, LLM ile yorum yapar, gerekirse kullanÄ±cÄ±ya sorar.
    """
    
    def __init__(self, llm_client: Optional[LLMClient] = None):
        self.llm_client = llm_client or LLMClient()
        self.error_analyzer = ErrorAnalyzer(None)
        self.learning_memory = []  # KullanÄ±cÄ±dan Ã¶ÄŸrenilenler
    
    def analyze_mistake_and_think(
        self,
        match_id: int,
        market_type: MarketType,
        predicted: str,
        actual: str,
        predicted_proba: Dict[str, float],
        match_context: Dict[str, Any],
        summary_stats: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        YanlÄ±ÅŸ tahminin nedenini dÃ¼ÅŸÃ¼nÃ¼r ve yorum yapar.
        MantÄ±klÄ± sebep bulamazsa kullanÄ±cÄ±ya sorar.
        """
        session = get_session()
        try:
            match = MatchRepository.get_by_id(session, match_id)
            if not match:
                return {"error": "Match not found"}
            
            home_team = TeamRepository.get_by_id(session, match.home_team_id)
            away_team = TeamRepository.get_by_id(session, match.away_team_id)
            
            # 1. Hata analizi yap
            error_analysis = self.error_analyzer.analyze_error(
                match_id, market_type, predicted, actual, predicted_proba, session
            )
            
            # 2. LLM'e "neden yanlÄ±ÅŸ oldu" diye sor
            llm_reasoning = self._ask_llm_why_wrong(
                match_context,
                predicted,
                actual,
                summary_stats,
                error_analysis
            )
            
            # 3. LLM'in cevabÄ± mantÄ±klÄ± mÄ± kontrol et
            is_reasonable = self._evaluate_reasoning_quality(llm_reasoning, error_analysis)
            
            result = {
                "error_analysis": error_analysis,
                "llm_reasoning": llm_reasoning,
                "is_reasonable": is_reasonable,
                "needs_user_input": not is_reasonable,
                "learning_points": []
            }
            
            # 4. MantÄ±klÄ± deÄŸilse kullanÄ±cÄ±ya sor
            if not is_reasonable:
                result["user_question"] = self._generate_user_question(
                    match_context, predicted, actual, error_analysis
                )
                result["learning_points"] = ["KullanÄ±cÄ±dan Ã¶ÄŸrenme gerekli"]
            
            # 5. Ã–ÄŸrenme noktalarÄ±nÄ± Ã§Ä±kar
            if is_reasonable:
                result["learning_points"] = self._extract_learning_points(
                    llm_reasoning, error_analysis
                )
            
            return result
        
        finally:
            session.close()
    
    def _ask_llm_why_wrong(
        self,
        match_context: Dict[str, Any],
        predicted: str,
        actual: str,
        summary_stats: Dict[str, Any],
        error_analysis: Dict[str, Any]
    ) -> str:
        """LLM'e neden yanlÄ±ÅŸ olduÄŸunu sorar"""
        
        prompt = f"""Bir futbol tahmin modeli yanlÄ±ÅŸ tahmin yaptÄ±. Neden yanlÄ±ÅŸ olduÄŸunu analiz et.

MaÃ§: {match_context.get('home_team')} vs {match_context.get('away_team')}
Tahmin Edilen: {predicted}
GerÃ§ek SonuÃ§: {actual}

Ä°statistikler:
{json.dumps(summary_stats, indent=2)}

Hata Analizi:
- Hata Kategorisi: {error_analysis.get('error_category', 'N/A')}
- GÃ¼ven: {error_analysis.get('confidence', 0):.2%}
- Sapma PayÄ±: {error_analysis.get('deviation', 0):.2%}
- Bias Tespit Edildi: {error_analysis.get('bias_detected', False)}
- Variance Problemi: {error_analysis.get('variance_issue', False)}

Eksik Feature'lar: {', '.join(error_analysis.get('missing_features', []))}

LÃ¼tfen ÅŸunlarÄ± analiz et:
1. Model neden bu tahmini yaptÄ±? (Hangi pattern'e dayandÄ±?)
2. GerÃ§ek sonuÃ§ neden farklÄ± oldu? (Hangi faktÃ¶r gÃ¶z ardÄ± edildi?)
3. Modelin formÃ¼lÃ¼nde/feature'larÄ±nda ne eksik veya yanlÄ±ÅŸ?
4. Bu hatadan nasÄ±l Ã¶ÄŸrenilebilir?

KÄ±sa ve net bir analiz yap (3-4 cÃ¼mle). EÄŸer kesin bir sebep bulamÄ±yorsan "BELIRSIZ" yaz."""

        try:
            response = self.llm_client.generate_explanation(
                match_context,
                {"predicted": predicted, "actual": actual},
                {**summary_stats, **error_analysis}
            )
            return response
        except Exception as e:
            logger.error(f"LLM reasoning hatasÄ±: {e}")
            return "LLM analizi yapÄ±lamadÄ±"
    
    def _evaluate_reasoning_quality(
        self,
        llm_reasoning: str,
        error_analysis: Dict[str, Any]
    ) -> bool:
        """LLM'in cevabÄ±nÄ±n mantÄ±klÄ± olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendirir"""
        
        # Belirsizlik kontrolÃ¼
        if "BELIRSIZ" in llm_reasoning.upper() or "bilmiyorum" in llm_reasoning.lower():
            return False
        
        # Ã‡ok kÄ±sa cevaplar mantÄ±ksÄ±z olabilir
        if len(llm_reasoning.split()) < 10:
            return False
        
        # Hata analizi ile uyumlu mu?
        if error_analysis.get("bias_detected") and "bias" not in llm_reasoning.lower():
            # Bias tespit edilmiÅŸ ama LLM bahsetmemiÅŸ - ÅŸÃ¼pheli
            if len(llm_reasoning) < 100:
                return False
        
        # Eksik feature'lar bahsedilmiÅŸ mi?
        missing_features = error_analysis.get("missing_features", [])
        if missing_features:
            mentioned = any(feat.lower() in llm_reasoning.lower() for feat in missing_features)
            if not mentioned and len(llm_reasoning) < 150:
                return False
        
        return True
    
    def _generate_user_question(
        self,
        match_context: Dict[str, Any],
        predicted: str,
        actual: str,
        error_analysis: Dict[str, Any]
    ) -> str:
        """KullanÄ±cÄ±ya sorulacak soruyu oluÅŸturur"""
        
        home_team = match_context.get("home_team", "Home Team")
        away_team = match_context.get("away_team", "Away Team")
        
        question = f"""
ğŸ¤” Model yanlÄ±ÅŸ tahmin yaptÄ± ve nedenini tam olarak anlayamadÄ±. YardÄ±m eder misin?

MaÃ§: {home_team} vs {away_team}
Tahmin: {predicted}
GerÃ§ek: {actual}

Hata Analizi:
- Kategori: {error_analysis.get('error_category', 'N/A')}
- GÃ¼ven: {error_analysis.get('confidence', 0):.2%}
"""
        
        if error_analysis.get("bias_detected"):
            question += "- âš ï¸ Bias problemi tespit edildi\n"
        
        if error_analysis.get("missing_features"):
            question += f"- ğŸ“‹ Eksik feature'lar: {', '.join(error_analysis['missing_features'])}\n"
        
        question += f"""
Soru: Model neden yanlÄ±ÅŸ tahmin yaptÄ±? Hangi faktÃ¶rÃ¼ gÃ¶z ardÄ± etti veya yanlÄ±ÅŸ yorumladÄ±?

Ã–rnek cevaplar:
- "Ev sahibi takÄ±mÄ±n son 3 maÃ§ta formu Ã§ok kÃ¶tÃ¼ydÃ¼ ama model bunu yeterince dikkate almadÄ±"
- "Bu iki takÄ±m arasÄ±nda Ã¶zel bir rekabet var, model bunu bilmiyor"
- "Hava koÅŸullarÄ±/seyirci faktÃ¶rÃ¼ Ã¶nemliydi"
- "TakÄ±m kadrosunda Ã¶nemli bir deÄŸiÅŸiklik vardÄ±"
- "Modelin formÃ¼lÃ¼nde X eksik"

CevabÄ±n: """
        
        return question
    
    def _extract_learning_points(
        self,
        llm_reasoning: str,
        error_analysis: Dict[str, Any]
    ) -> List[str]:
        """LLM'in analizinden Ã¶ÄŸrenme noktalarÄ±nÄ± Ã§Ä±karÄ±r"""
        points = []
        
        # Bias tespit edilmiÅŸse
        if error_analysis.get("bias_detected"):
            points.append("Bias dÃ¼zeltmesi gerekli")
        
        # Eksik feature'lar
        missing = error_analysis.get("missing_features", [])
        if missing:
            points.append(f"Eklenecek feature'lar: {', '.join(missing)}")
        
        # LLM'in Ã¶nerileri
        if "formÃ¼l" in llm_reasoning.lower() or "formula" in llm_reasoning.lower():
            points.append("Model formÃ¼lÃ¼ gÃ¼ncellenmeli")
        
        if "feature" in llm_reasoning.lower():
            points.append("Feature engineering gerekli")
        
        return points
    
    def process_user_feedback(
        self,
        match_id: int,
        market_type: MarketType,
        user_feedback: str,
        error_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        KullanÄ±cÄ±dan gelen geri bildirimi iÅŸler ve Ã¶ÄŸrenir.
        """
        learning_entry = {
            "match_id": match_id,
            "market_type": market_type.value,
            "user_feedback": user_feedback,
            "error_analysis": error_analysis,
            "timestamp": datetime.now().isoformat(),
            "learned": False
        }
        
        # Geri bildirimden Ã¶ÄŸrenme noktalarÄ±nÄ± Ã§Ä±kar
        learning_points = self._extract_learning_from_feedback(user_feedback, error_analysis)
        learning_entry["learning_points"] = learning_points
        
        # Ã–ÄŸrenme hafÄ±zasÄ±na ekle
        self.learning_memory.append(learning_entry)
        
        logger.info(f"ğŸ“š KullanÄ±cÄ± geri bildirimi kaydedildi: {user_feedback[:50]}...")
        logger.info(f"ğŸ’¡ Ã–ÄŸrenme noktalarÄ±: {learning_points}")
        
        return {
            "saved": True,
            "learning_points": learning_points,
            "memory_size": len(self.learning_memory)
        }
    
    def _extract_learning_from_feedback(
        self,
        user_feedback: str,
        error_analysis: Dict[str, Any]
    ) -> List[str]:
        """KullanÄ±cÄ± geri bildiriminden Ã¶ÄŸrenme noktalarÄ±nÄ± Ã§Ä±karÄ±r"""
        points = []
        feedback_lower = user_feedback.lower()
        
        # Feature eksikliÄŸi bahsedilmiÅŸ mi?
        if "eksik" in feedback_lower or "missing" in feedback_lower:
            if "feature" in feedback_lower or "Ã¶zellik" in feedback_lower:
                points.append("Yeni feature eklenmeli")
        
        # FormÃ¼l hatasÄ± bahsedilmiÅŸ mi?
        if "formÃ¼l" in feedback_lower or "formula" in feedback_lower:
            points.append("Model formÃ¼lÃ¼ gÃ¼ncellenmeli")
        
        # TakÄ±m Ã¶zel durumu
        if "Ã¶zel" in feedback_lower or "special" in feedback_lower or "rekabet" in feedback_lower:
            points.append("TakÄ±m Ã¶zel durumlarÄ± feature'a eklenmeli")
        
        # Form/trend
        if "form" in feedback_lower or "trend" in feedback_lower:
            points.append("Form trendi feature'Ä± gÃ¼Ã§lendirilmeli")
        
        # Ev sahibi avantajÄ±
        if "ev sahibi" in feedback_lower or "home" in feedback_lower:
            points.append("Ev sahibi avantajÄ± feature'Ä± gÃ¼ncellenmeli")
        
        return points
    
    def apply_learned_knowledge(
        self,
        match_context: Dict[str, Any],
        current_features: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Ã–ÄŸrenilen bilgileri mevcut tahminlere uygular.
        """
        enhanced_features = current_features.copy()
        
        # Ã–ÄŸrenme hafÄ±zasÄ±ndan ilgili bilgileri bul
        home_team = match_context.get("home_team", "")
        away_team = match_context.get("away_team", "")
        
        relevant_learnings = [
            entry for entry in self.learning_memory
            if (home_team in str(entry.get("error_analysis", {})) or
                away_team in str(entry.get("error_analysis", {})))
        ]
        
        if relevant_learnings:
            logger.info(f"ğŸ§  {len(relevant_learnings)} ilgili Ã¶ÄŸrenme bulundu")
            
            # Ã–ÄŸrenilen pattern'leri feature'lara ekle
            for learning in relevant_learnings[-5:]:  # Son 5 Ã¶ÄŸrenme
                feedback = learning.get("user_feedback", "")
                if "form" in feedback.lower():
                    enhanced_features["learned_form_adjustment"] = 1.1
                if "Ã¶zel" in feedback.lower() or "special" in feedback.lower():
                    enhanced_features["learned_special_case"] = True
        
        return enhanced_features
    
    def get_learning_summary(self) -> Dict[str, Any]:
        """Ã–ÄŸrenme Ã¶zetini dÃ¶ndÃ¼rÃ¼r"""
        return {
            "total_learnings": len(self.learning_memory),
            "recent_learnings": self.learning_memory[-10:] if len(self.learning_memory) > 10 else self.learning_memory,
            "learning_topics": list(set([
                point
                for entry in self.learning_memory
                for point in entry.get("learning_points", [])
            ]))
        }







