"""
JSON HYPE FILLER - HIZLI KAYIT (INSTANT SAVE)
- Listenin EN SONUNDAN baÅŸlar.
- Her 5 maÃ§ta bir diske kaydeder (AnlÄ±k deÄŸiÅŸim gÃ¶rÃ¼nÃ¼r).
- Eksik verileri (null) doldurur.
- 10 Thread ile hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r.
"""
import sys
import os
import json
from pathlib import Path
from datetime import datetime
import time
from typing import Dict, List
from concurrent.futures import ThreadPoolExecutor, as_completed
import socket

# Konsol Ã§Ä±ktÄ± ayarlarÄ±
if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

# Proje dizin ayarlarÄ±
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root.parent))
sys.path.insert(0, str(project_root))

from src.ingestion.alternative_hype_scraper import AlternativeHypeScraper

# --- AYARLAR ---
JSON_FILE = "football_brain_export.json"
MAX_WORKERS = 100   # HÄ±z: 10 Motorlu
BATCH_SIZE = 1000     # DÃœZELTME: Her 5 maÃ§ta bir kaydeder (Sonucu hemen gÃ¶rmek iÃ§in)

def get_json_path():
    """DosyanÄ±n tam yolunu bulur"""
    # 1. Ã‡alÄ±ÅŸma dizinine bak
    path = Path(os.getcwd()) / JSON_FILE
    if path.exists():
        return path
    
    # 2. DosyanÄ±n yanÄ±na bak
    path = Path(__file__).parent / JSON_FILE
    if path.exists():
        return path
        
    # 3. Proje kÃ¶kÃ¼ne bak
    path = Path(project_root) / JSON_FILE
    return path

def save_to_disk(full_data: Dict):
    """Veriyi diske yazar ve bilgi verir"""
    path = get_json_path()
    try:
        # GeÃ§ici bir dosyaya yazÄ±p sonra ismini deÄŸiÅŸtirmek daha gÃ¼venlidir ama
        # Windows'ta bazen sorun Ã§Ä±karÄ±r, direkt yazÄ±yoruz.
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(full_data, f, ensure_ascii=False, indent=2, default=str)
        return True
    except PermissionError:
        print(f"âŒ HATA: Dosya ÅŸu an aÃ§Ä±k! LÃ¼tfen JSON dosyasÄ±nÄ± kapatÄ±n.", flush=True)
        return False
    except Exception as e:
        print(f"âŒ KAYIT HATASI: {e}", flush=True)
        return False

# Ä°nternet baÄŸlantÄ±sÄ±nÄ± kontrol eden fonksiyon
def check_internet_connection():
    try:
        # Google DNS sunucusuna baÄŸlanmayÄ± dene
        socket.create_connection(("8.8.8.8", 53), timeout=5)
        return True
    except OSError:
        return False

def scrape_match_data(match: Dict):
    """
    Tek bir maÃ§ iÃ§in veriyi Ã§eker.
    """
    home = match.get('home_team_name')
    away = match.get('away_team_name')
    league = match.get('league_name')
    date_str = match.get('match_date')
    
    if not home or not away:
        return None

    print(f"â¡ï¸ BaÅŸladÄ±: {home} vs {away}", flush=True)

    # Ä°NATÃ‡I MOD
    while True:
        try:
            # Ä°nternet baÄŸlantÄ±sÄ±nÄ± kontrol et
            if not check_internet_connection():
                print("âš ï¸ Ä°nternet baÄŸlantÄ±sÄ± yok. Yeniden baÄŸlanmayÄ± bekliyor...", flush=True)
                time.sleep(10)  # 10 saniye bekle
                continue

            scraper = AlternativeHypeScraper()
            match_date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            result = scraper.get_match_hype(league, home, away, match_date)
            return result
        except Exception as e:
            print(f"âš ï¸ HATA ({home} vs {away}): {e}. Bekleniyor...", flush=True)
            time.sleep(3)  # Hata durumunda bekleme sÃ¼resi

def main():
    print("="*60)
    print("ğŸš€ JSON HYPE DOLDURUCU (HIZLI KAYIT MODU)")
    print(f"ğŸ“‚ Hedef Dosya: {get_json_path().name}")
    print(f"ğŸ’¾ KayÄ±t SÄ±klÄ±ÄŸÄ±: Her {BATCH_SIZE} maÃ§ta bir")
    print("="*60, flush=True)

    # 1. DOSYAYI YÃœKLE
    path = get_json_path()
    try:
        with open(path, 'r', encoding='utf-8') as f:
            full_data = json.load(f)
    except Exception as e:
        print(f"âŒ Kritik Hata: Dosya okunamadÄ±! {e}")
        return
    
    # Matches referansÄ±nÄ± al
    all_matches = full_data.get('data', {}).get('matches', [])
    
    if not all_matches:
        print("âŒ Dosyada maÃ§ bulunamadÄ±!")
        return

    # 2. Ä°ÅLENECEK LÄ°STEYÄ° HAZIRLA (TERS Ã‡EVÄ°R)
    print("ğŸ”„ Liste analiz ediliyor (Sondan baÅŸa)...")
    
    # (Index, Match) Ã§iftleri
    indexed_matches = list(enumerate(all_matches))
    reversed_matches = indexed_matches[::-1]
    
    # Eksik hype verisi olan ilk kayÄ±ttan baÅŸlamak iÃ§in listeyi filtrele
    first_missing_index = None
    for idx, m in indexed_matches:
        is_hype_missing = (m.get('hype_updated_at') is None) or \
                          (m.get('home_support') is None) or \
                          (m.get('total_tweets') == 0)

        if is_hype_missing:
            first_missing_index = idx
            break

    if first_missing_index is not None:
        indexed_matches = indexed_matches[first_missing_index:]
        reversed_matches = indexed_matches[::-1]
    else:
        print("ğŸ‰ YapÄ±lacak iÅŸ kalmadÄ±! TÃ¼m veriler zaten dolu.", flush=True)
        return

    # Devam eden iÅŸlemler iÃ§in gÃ¼ncellenmiÅŸ listeyi kullan
    todo_list = []
    for idx, m in reversed_matches:
        is_hype_missing = (m.get('hype_updated_at') is None) or \
                          (m.get('home_support') is None) or \
                          (m.get('total_tweets') == 0)

        has_score = (m.get('home_score') is not None)

        if has_score and is_hype_missing:
            todo_list.append((idx, m))

    if not todo_list:
        print("ğŸ‰ YapÄ±lacak iÅŸ kalmadÄ±! TÃ¼m veriler zaten dolu.", flush=True)
        return

    print(f"ğŸ“‹ Doldurulacak {len(todo_list)} eksik maÃ§ bulundu.", flush=True)
    print("-" * 40)

    # 3. Ä°ÅLEME BAÅLA
    processed_count = 0
    
    # Batch dÃ¶ngÃ¼sÃ¼
    for i in range(0, len(todo_list), BATCH_SIZE):
        batch = todo_list[i : i + BATCH_SIZE]
        matches_modified_count = 0
        
        print(f"\nâš¡ Grup Ä°ÅŸleniyor ({i+1} - {i+len(batch)})...", flush=True)
        
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_idx = {
                executor.submit(scrape_match_data, item[1]): item[0] 
                for item in batch
            }
            
            for future in as_completed(future_to_idx):
                original_idx = future_to_idx[future]
                result = future.result()
                
                if result:
                    # DÄ°KKAT: DoÄŸrudan hafÄ±zadaki ana listeyi gÃ¼ncelliyoruz
                    target_match = all_matches[original_idx]
                    
                    target_match['home_support'] = result.get("home_support", 0.5)
                    target_match['away_support'] = result.get("away_support", 0.5)
                    target_match['sentiment_score'] = result.get("sentiment_score", 0.0)
                    target_match['total_tweets'] = result.get("total_mentions", 0)
                    target_match['hype_updated_at'] = datetime.now().isoformat()
                    
                    matches_modified_count += 1
                    
                    # Log
                    teams = f"{target_match['home_team_name']} vs {target_match['away_team_name']}"
                    mentions = target_match['total_tweets']
                    print(f"âœ… [{original_idx}] {teams} | ğŸ“¢ {mentions}", flush=True)

        # 4. KAYIT (HER 5 MAÃ‡TA BÄ°R)
        if matches_modified_count > 0:
            print("ğŸ’¾ Dosyaya yazÄ±lÄ±yor...", flush=True)
            if save_to_disk(full_data):
                processed_count += matches_modified_count
                print(f"âœ… JSON GÃœNCELLENDÄ°! (Toplam: {processed_count} maÃ§ iÅŸlendi)", flush=True)
            else:
                print("âš ï¸ DÄ°KKAT: KayÄ±t yapÄ±lamadÄ± (Dosya aÃ§Ä±k olabilir)", flush=True)
        
        time.sleep(0.5)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ›‘ Durduruldu.")


